[{"authors":null,"categories":null,"content":"One of the greatest Star Trek episodes is titled Darmok in Star Trek: The Next Generation. It has the hallmarks of a great Star Trek: TNG episode: a first contact between two civilizations and a dilemma that is not solved by violence but by thinking and understanding.\nOne of the nicest logic programming languages is miniKanren. This is due to the fact that it is a small, relatively easy to understand Logic Programming (LP) language and has implementations in many programming languages. This later feature allows for logic programming features to be used in many different environments, as a logic programming Domain-Specific language (DSL).\nA popular implementation of miniKanren is the core.logic library of the Clojure programming language. In this article we aim to introduce miniKanren/core.logic by encoding story elements of the Darmok episode of Star Trek: TNG (some spoilers for the episode will follow).\nThe episode is based around the fact that the Federation and the Tamarian people aim to establish successful first contact with each other. From the Federation, the crew of the starship Enterprise are sent to the planet El-Adrel where a Tamarian ship awaits them. Unfortunately attempts for communication fail from both sides and lead to some dangerous situations. The difficulty of communication arises from the fact that Tamarians communicate exclusively through allegory. This means that it is not just enough to decipher the words used in the Tamarian language, but the crew of the Enterprise must also understand the myths and historical events to which these allegories refer to. Within the episode multiple allegories are used by the Tamarians, such as with the phrase \u0026ldquo;Darmok and Jalad at Tanagra\u0026rdquo;, that utterly baffle the crew at first. However through shared dangers and cooperation understanding eventually comes. In the end successful first contact is made by the captain of the Enterprise, Picard and the captain of the Tamarian ship, Darmok. This is captured by the newly coined allegory for first contact in the Tamarian language: \u0026ldquo;Picard and Dathon at El-Adrel\u0026rdquo;.\nIn this article we will use core.logic to write a logic program to represent the allegories used in the Darmok episode, and to generate templates of the Darmok story through a sequence of allegories. A logic program is a bit different than programs most people are used to. Instead of giving precise instructions to the computer one instead writes a goal, or a group of goals, that provide some logical restrictions on what one intends to achieve. With these goals the logic programming system can find the right answers. Note that the source for the code used this article can be found here in case you want to experiment along while reading this article.\nLet\u0026rsquo;s start off with a small logic program that can translate the Tamarian allegory that represents cooperation, the phrase \u0026ldquo;Darmok and Jalad at Tanagra\u0026rdquo;. We aim to translate this allegory to an equivalent allegory based on a human myth, as well as the English translation for it: \u0026ldquo;cooperation\u0026rdquo;.\nIn order to do this we give the Clojure definition of this goal as a logic program, then explain each element of it and how to use it.\n(defn cooperation [tam hum eng] (l/conde [(l/== [tam] [\u0026quot;Darmok and Jalad at Tanagra.\u0026quot;]) (l/== [hum] [\u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot;]) (l/== [eng] [\u0026quot;cooperation\u0026quot;])]))  First lets decipher the above definition. For people, unfamiliar with Clojure, the form (defn cooperation [tam hum eng] ... ) defines a function named cooperation with the parameters tam hum eng. The part with (l/conde ... ) is a shorthand for (core.logic/conde ... ); we will use l as the abbreviation for the core.logic namespace in the rest of this article. This l/conde part functions as a way to connect various goals together. It creates a disjunction (elements separated by OR) of separate vectors of goals which it considers as conjunction (elements separated by AND). For people a bit familiar with boolean logic this a way to write a Disjunctive Normal Form. To give a very simplified example the form (l/conde [A B] [C] ) with the goals A, B, C can be seen as a way to find the case where (A 'AND' B) 'OR' C holds. In the previous example l/conde is called on a single vector of elements [(l/== [tam] [\u0026quot;Darmok and Jalad at Tanagra.\u0026quot;]) (l/== [hum] [\u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot;]) (l/== [eng] [\u0026quot;cooperation\u0026quot;])], meaning that this function wants each of the goals: (l/== [tam] [\u0026quot;Darmok and Jalad at Tanagra.\u0026quot;]) AND (l/== [hum] [\u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot;]) AND (l/== [eng] [\u0026quot;cooperation\u0026quot;]) fulfilled.\nSo now we know that this function takes three parameters and wants to ensure that the three goals all have to be met. But what do the goals themselves mean? They all have a similar structure using the equality in core logic, l/==, which aims to unify the elements. Unification is a core part of a logic programming system and it is used to constrain elements to the same possible values. For the first example (l/== [tam] [\u0026quot;Darmok and Jalad at Tanagra.\u0026quot;]), the unification aims to ensure that the variable tam has the value of the string \u0026quot;Darmok and Jalad at Tanagra.\u0026quot;, which can be seen as the Tamarian phrase for cooperation. The other goals do this unification for the human mythology equivalent: \u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot; of this allegory, as well for the English word \u0026quot;cooperation\u0026quot;, for the variables hum and eng, respectively.\nWe have now given an anatomy of this logic program that does unification on phrases relating to cooperation, but how do we use it? For this we need two things, a set of logic variables and a way to tell the system to run the logic program. The function l\\run* does exactly that, which for the given set of parameters try to find all examples for which the goals are fulfilled.\nSo if we evaluate the following code:\n(l/run* [tam hum eng] (cooperation tam hum eng))  we get the following:\n([\u0026quot;Darmok and Jalad at Tanagra.\u0026quot; \u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot; \u0026quot;cooperation\u0026quot;])  What l\\run* is doing is taking a given list of logic variables, and tries to list all the possible values these variables can take. Here it only lists a single possible set of values for the variables tam, hum and eng. This should not be surprising as there is only exactly one way each of the variables tam, hum, and eng can be fulfilled by the \u0026ldquo;cooperation\u0026rdquo; goal based on the definition we gave above. The variable tam gets unified with the string value \u0026quot;Darmok and Jalad at Tanagra.\u0026quot;, hum with \u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot; and eng with \u0026quot;cooperation\u0026quot;.\nIn the previous case we used only \u0026lsquo;fresh\u0026rsquo; logic variables (variables that have no constraints placed upon their possible values yet), but instead we can also use a specific value in our goal instead. In the following example we only have two variables. Instead of a variable for first parameter used in the cooperation goal we give the string \u0026quot;Darmok and Jalad at Tanagra.\u0026quot; already:\n(l/run* [hum eng] (cooperation \u0026quot;Darmok and Jalad at Tanagra.\u0026quot; hum eng))  which gives the following result:\n([\u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot; \u0026quot;cooperation\u0026quot;])  There are only two variables listed in the answer, as there are only two variables given for run to check in our initial case. Otherwise the answer is exactly what we would expect, as there are only one possible way these variables can be bound in our logic program.\nNow lets try a run where there are no possible valid answers, giving the word \u0026quot;challenge\u0026quot; as a parameter:\n(l/run* [tam hum eng] (cooperation tam hum \u0026quot;challenge\u0026quot;))  This returns an empty list of answers: (), as there are no ways to unify the word \u0026quot;challenge\u0026quot; inside the goal of cooperation.\nGiven we got the basics of logic programs covered, lets expand our example into something more complex.\nInstead of one single allegory, we now define five of them based on the various allegories used in the Darmok episode. The functions representing these goals are all named after the English word translation: failure, common-enemy, cooperation, successful-cooperation and successful-first-contact. They all follow the same structure as the cooperation allegory we previously examined in detail. In addition we also define a function for representing any allegory, aptly named allegory, that is a goal that can be fulfilled by any of the allegories named above.\n(defn failure [tam hum eng] (l/conde [(l/== [tam] [\u0026quot;Shaka, when the walls fell.\u0026quot;]) (l/== [hum] [\u0026quot;Gilgamesh, his plant eaten by a snake.\u0026quot;]) (l/== [eng] [\u0026quot;failure\u0026quot;])])) (defn common-enemy [tam hum eng] (l/conde [(l/== [tam] [\u0026quot;Beast at Tanagra.\u0026quot;]) (l/== [hum] [\u0026quot;Bull of Heaven.\u0026quot;]) (l/== [eng] [\u0026quot;common-enemy\u0026quot;])])) (defn cooperation [tam hum eng] (l/conde [(l/== [tam] [\u0026quot;Darmok and Jalad at Tanagra.\u0026quot;]) (l/== [hum] [\u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot;]) (l/== [eng] [\u0026quot;cooperation\u0026quot;])])) (defn successful-cooperation [tam hum eng] (l/conde [(l/== [tam] [\u0026quot;Darmok and Jalad on the ocean.\u0026quot;]) (l/== [hum] [\u0026quot;Gilgamesh and Ekidu, after the Bull's defeat.\u0026quot;]) (l/== [eng] [\u0026quot;successful-cooperation\u0026quot;])])) (defn successful-first-contact [tam hum eng] (l/conde [(l/== [tam] [\u0026quot;Picard and Dathon at El-Adrel.\u0026quot;]) (l/== [hum] [\u0026quot;Picard and Dathon at El-Adrel.\u0026quot;]) (l/== [eng] [\u0026quot;successful-first-contact\u0026quot;])])) (defn allegory [tam hum eng] (l/conde [(failure tam hum eng)] [(common-enemy tam hum eng)] [(cooperation tam hum eng)] [(successful-cooperation tam hum eng)] [(successful-first-contact tam hum eng)]))  There should not be any very surprising elements in this part, but we give two quick observations before continuing.\nFirst, the human equivalent for Tamarian allegories are based on the Gilgamesh story, which is also explicitly mentioned in the episode and provides a way for Caption Picard to connect with the Tamarian Captain Dathon. The only exception to this \u0026quot;Picard and Dathon at El-Adrel.\u0026quot; which is an allegory coined at the end of the episode as a term for first contact between cultures, and can be seen as a historical event from a human perspective as well.\nSecond, to reiterate how l/conde works with choices, we remark that each of the named allegories in the allegory function are in their own vector (indicated by each goal inside their own [] brackets). This indicates that any of failure, common-enemy, cooperation, successful-cooperation or successful-first-contact can fulfill the goal of allegory.\nWe can test this later notion by running a short logic program for finding all possible allegories:\n(l/run* [tam hum eng] (allegory tam hum eng))  which returns:\n([\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Gilgamesh, his plant eaten by a snake.\u0026quot; \u0026quot;failure\u0026quot;] [\u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Bull of Heaven.\u0026quot; \u0026quot;common-enemy\u0026quot;] [\u0026quot;Darmok and Jalad at Tanagra.\u0026quot; \u0026quot;Gilgamesh and Ekidu at Uruk.\u0026quot; \u0026quot;cooperation\u0026quot;] [\u0026quot;Darmok and Jalad on the ocean.\u0026quot; \u0026quot;Gilgamesh and Ekidu, after the Bull's defeat.\u0026quot; \u0026quot;successful-cooperation\u0026quot;] [\u0026quot;Picard and Dathon at El-Adrel.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot; \u0026quot;successful-first-contact\u0026quot;])  This shows five possible answers because, as mentioned, any of the above allegories can fulfill the given goal. By default l/run* will list all possible answers for a given logic program, which is a very powerful feature for exhaustively searching for solutions to a given problem. However this list can be large, and even infinite! In such scenarios there is a way to limit the answers to a certain number when search: by using l/run directly followed by the number of answers we want returned.\nFor example, the call:\n(l/run 2 [tam hum eng] (allegory tam hum eng))  will return only two possible answers:\n([\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Gilgamesh, his plant eaten by a snake.\u0026quot; \u0026quot;failure\u0026quot;] [\u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Bull of Heaven.\u0026quot; \u0026quot;common-enemy\u0026quot;])  Now as we are getting a bit more familiar with the allegories in this example, we do not want to write out all three versions of each allegory each time. We can do this by defining a new goal allegory-short that succeeds for any phrase that identifies one of the 5 allegories:\n(defn allegory-tam [tam] (l/fresh [x y] (allegory tam x y))) (defn allegory-hum [hum] (l/fresh [x y] (allegory x hum y))) (defn allegory-eng [eng] (l/fresh [x y] (allegory x y eng))) (defn allegory-short [x] (l/conde [(allegory-tam x)] [(allegory-hum x)] [(allegory-eng x)]))  The allegory-short function was defined by writing out the three scenarios by which a phrase could be part of an allegory: it is either the Tamarian allegory, the Human allegory or the English translation. The only new structure we use here from core.logic is l/fresh which lets us introduce new (fresh) logic variables which have no binding as of yet. When using the various forms of l/run the parameters for the function are automatically given as fresh variables, but this function allows us to create then inside other parts of the logic program as well.\nNow if we want to list, for example, five possible phrases that form part of an allegory we can call:\n(allegory-short x))  which will return five of the possible terms that are used as part of allegories.\n(\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Darmok and Jalad at Tanagra.\u0026quot; \u0026quot;Gilgamesh, his plant eaten by a snake.\u0026quot; \u0026quot;failure\u0026quot;)  With all the functions for logic programming we built up, lets try our hand at creating a logic program that generates a variants the Darmok story, expressed through a sequence of allegories. In this scenario, much like in the episode any phrase, Tamarian or Human allegory or their English equivalent, could be used to describe parts of the story. In essence we can represent the story as a list of phrases, for example: (\u0026ldquo;failure\u0026rdquo;, \u0026ldquo;Beast at Tanagra.\u0026rdquo; \u0026ldquo;Darmok and Jalad at Tanagra.\u0026rdquo; \u0026ldquo;successful-first-contact\u0026rdquo; ).\nWe could put many restrictions on the order of the phrases but for the sake of brevity, we just want to ensure that each story starts with a phrase for failure and ends with a phrase for successful-first-contact much like the structure of the actual episode. In addition let\u0026rsquo;s assume our stories are only five phrases long.\nWe can now define logic program to generate such stories as follows:\n(defn failure-any [x] (l/fresh [a1 a2 a3] (l/conde [(failure x a1 a2)] [(failure a1 x a2)] [(failure a1 a2 x)]))) (defn successful-first-contact-any [x] (l/fresh [a1 a2 a3] (l/conde [(successful-first-contact x a1 a2)] [(successful-first-contact a1 x a2)] [(successful-first-contact a1 a2 x)]))) (defn five-element-story [x1, x2, x3, x4, x5] (l/fresh [a1 a2 a3] (l/conde [(failure-any x1) (allegory-short x2) (allegory-short x3) (allegory-short x4) (successful-first-contact-any x5)])))  Every construct we used to build these functions should be familiar. We just needed to define two special versions of our goals for the shorthand version of allegories: one for failure and one for successful first contact.\nFor example if we want five solutions that fulfill all the criteria for such stories we can call the following code:\n(l/run 5 [x1 x2 x3 x4 x5] (five-element-story x1 x2 x3 x4 x5))  which for example could return:\n([\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;] [\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;] [\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;successful-first-contact\u0026quot;] [\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;] [\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;])  As one can see the logic program will exhaustively go through all the possible ways the goals can fulfilled and list them up to limit given as a parameter for l/run. The results are not necessarily unique if there are multiple ways to fulfill the goals. This can be seen in the first and second answers as the phrase \u0026ldquo;Picard and Dathon at El-Adrel.\u0026rdquo; is both the Tamarian and Human allegory for successful first contact.\nThe above restrictions allow for a lot of the same allegories used within the story. For this, one can define new restrictions and further fine tune the story generation. For example, one can create restrictions on the number of duplicate phrases used, or could ensure that there is more diversity in the phrase type (Tamarian, Human, English) is used. Declaring new restrictions, combining them with existing ones and using the same mechanism to derive any number of answers is one of the core strengths of a logic programming system such as core.logic.\nAs a final example to show how logic programming can be embedded into a (regular) program, we create a logic program inside a regular Clojure function that creates n-number of stories of a given length. Take a quick look at the following code:\n(defn n-element-story [nr-of-elements stories] (let [vars (repeatedly nr-of-elements l/lvar) first-var (first vars) middle (drop-last (rest vars)) last-var (last vars)] (l/run stories [q] (l/conde [(l/== q vars) (l/distincto q) (failure-any first-var) (successful-first-contact-any last-var) (l/everyg allegory-short middle)]))))  Without going too in-depth on every part of this function, what it does is programmatically create n-number of fresh variables based on the given parameter. It than unifies these with the parameters of a run execution inside the function and returns them. For example, six stories of four elements can be requested by the call:\n(n-element-story 4 6)  which will result in the stories:\n((\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Darmok and Jalad at Tanagra.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;) (\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Darmok and Jalad on the ocean.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;) (\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Gilgamesh, his plant eaten by a snake.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;) (\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;failure\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;) (\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Bull of Heaven.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;) (\u0026quot;Shaka, when the walls fell.\u0026quot; \u0026quot;Darmok and Jalad at Tanagra.\u0026quot; \u0026quot;Beast at Tanagra.\u0026quot; \u0026quot;Picard and Dathon at El-Adrel.\u0026quot;))  There you have it, a very quick overview of using core.logic for logic programming. If you would like to experiment further the code used in this article is available. Here we only scratched the surface of what is possible in a logic programming environments such as core.logic. Feel free to check it out, or any other miniKanren implementation available in your language.\nI hope that, much like the Darmok episode, this article has expanded your horizons on communicating. Logic programming is a very interesting, and often underutilized programming paradigm, and core.logic/miniKanren is a great system to get started with it. I hope that this, perhaps first, contact with Logic Programming or core.logic aids you in your future endeavors.\n","date":1580598000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549062000,"objectID":"1083cd56e134adbdb8fa280c131271da","permalink":"https://www.newresalhaider.com/post/darmok-core-logic/","publishdate":"2020-02-02T00:00:00+01:00","relpermalink":"/post/darmok-core-logic/","section":"post","summary":"A tutorial to logic programming using miniKanren and core.logic by representing and using the allegory based Tamarian language from the Start Trek Next-Generation Episode Darmok.\n","tags":["AI","logic programming","core.logic","kanren","clojure","Star Trek"],"title":"Darmok in core.logic","type":"post"},{"authors":null,"categories":null,"content":"Scooby Doo is mystery horror cartoon series in which a group of teenagers named Fred, Daphne, Velma and Shaggy alongside the titular Great Dane named Scooby-Doo, ride around in their van named \u0026ldquo;The Mystery Machine\u0026rdquo; solving mysteries. The episodes of the show generally follow a set structure. First their van tends to break down near a place apparently haunted by a ghost or another supernatural creature. They would offer to solve the mystery behind the existence of the monster and start looking for clues. The monster tries to scare them away while they find various pieces of evidence relating to it, all pointing to the fact that the monster is not real. At a certain point the creature starts to chase them until they can trap or otherwise incapacitate it. Finally they figure out that the monster is person in a costume who put the mystery in place to scare people away for some (financial) reason, and who would have gotten away with it \u0026ldquo;if not for them meddling kids\u0026rdquo;.\nWhile having a van named The Mystery Machine can help solving mysteries, we can turn our computer into a mystery solving machine as well. We can represent possible stories in a Scooby Doo episode using some logical facts (e.g. a each adventure has a monster in it) as well as probabilities (e.g. there is a 40% chance a monster will be a ghost). In particular, we can use a probabilistic logic programming language, namely ProbLog to guide us through a scenario of a Scooby Doo story.\nFirst let\u0026rsquo;s start off with a basic scenario on how a Scooby Doo adventure starts. In general there is usually some sort of an issue why the group must stop during their travels. Although there are many possible causes for this in the cartoon, here we represent three of them. Either they get a flat tire, they unexpectedly run out of gas, or there is some engine trouble that they have to deal with. For each of these scenarios there is a probability with which they happen. This probability we assume is 40% for a flat tire, 30% for being unexpectedly out of gas, and 60% for having an engine trouble. These are the probabilistic facts in our scenario, as each of these facts have a probability attached to them with which they occur. If any of these facts hold, it will lead to an adventure. This type of knowledge we can represent as a rule. Finally, we aim to query this scenario for the probability that an adventure will occur.\nIn ProbLog the above scenario can be represented as follows:\n% Probabilistic facts: 0.4::flat_tire. 0.3::out_of_gas. 0.6::engine_trouble. % Rules: adventure_start :- flat_tire. adventure_start :- out_of_gas. adventure_start :- engine_trouble. % Queries:. query(adventure_start).  As one can see, a ProbLog program is a combination of probabilistic facts, rules and queries (with comments in lines following %). Probabilistic facts represent the facts of the domain with an attached probability between 0 and 1. Rules are deterministic rules (i.e. they have no probabilities attached) that show the system how new facts can be inferred from existing ones. Finally queries allow us to ask the program questions, such as the probabilities for a certain fact occuring. These program elements are similar to those employed in Prolog, where a program consists of facts, rules and queries, with the main difference that there are probabilities attached to each fact.\nWe can use infer new facts from these probabilistic facts using rules. For example, if we want to infer the probability of an adventure the query: query(adventure). will return the probability 0.832.\nNow we can make our Scooby Doo scenario a bit more complex. Suppose the group starts an adventure, after their van stopped working somehow, and they quickly realize that there is a mystery in the area. The location of this mystery is either an abandoned mansion, a local museum, an old theme park, or a nearby farm. We set the probabilities for each of these locations occurring at 0.3 for the abandoned mansion, 0.3 for a local museum, 0,2 for an old theme park and 0.2 for the nearby farm. We also assume that there is only one mystery location in each adventure.\nIn order to express the requirements for the adventure locations succinctly, we make use of a feature called annotated disjunctions. This allows for a more readable way to state that only one of the stated choices holds true, with a given probability. Below is the ProbLog program extended to include this information.\n% Probabilistic facts: 0.4::flat_tire. 0.3::out_of_gas. 0.6::engine_trouble. 0.3::monster_location(abandoned_mansion); 0.3::monster_location(local_museum); 0.2::monster_location(old_theme_park); 0.2::monster_location(nearby_farm). % Rules: adventure_start :- flat_tire. adventure_start :- out_of_gas. adventure_start :- engine_trouble. adventure :- monster_location(X), adventure_start. two_locations :- monster_location(X), monster_location(Y), X \\== Y. % Queries:. query(two_locations).  There are two other new concepts that we showcase here. One is using variables, notably the X in monster_location(X), which helps to express that the values used for this variable all express the monster\u0026rsquo;s location. The other is the use of restrictions in the use two_locations to showcase that the probability for two monster locations occurring at once is 0. There are number of built-ins that one can use for defining Problog models. In this case we use to define a rule to express that the two_locations fact should be derived if there are two distinct monster locations. Given the example above, due to the use of an annotated disjunction for defining the monster location, the query query(two_locations). will correctly probability of 0 for the chance of two monster locations at the same time.\nThe final ingredient for a Scooby Doo story that we represent in this article is the monster. There are five types of monsters that can occur: a Mummy, a Zombie, a Ghost, a Swamp Monster and a Headless Horseman. The chance at which these monsters occur is dependent on the current location. In the stories that we represent only 1 monster can occur in an adventure.\nSuch cases can also be represented with annotated disjunctions, but they are now used as the head (which is the left hand side portion of the rule, with the :- sign separating the two sides). This allows us to express the conditions, i.e. the monster locations, that is required for these facts. See our final example for the probabilities of monsters given the locations:\n% Probabilistic facts: 0.4::flat_tire. 0.3::out_of_gas. 0.6::engine_trouble. 0.3::monster_location(abandoned_mansion); 0.3::monster_location(local_museum); 0.2::monster_location(old_theme_park); 0.2::monster_location(nearby_farm). % Rules: adventure_start :- flat_tire. adventure_start :- out_of_gas. adventure_start :- engine_trouble. 0.4::monster(ghost); 0.4::monster(vampire); 0.2::monster(zombie) :- monster_location(abandoned_mansion). 0.5::monster(mummy); 0.2::monster(headless_horseman); 0.3::monster(ghost) :- monster_location(local_museum). 0.5::monster(zombie); 0.4::monster(ghost); 0.1::monster(mummy) :- monster_location(old_theme_park). 0.4::monster(ghost); 0.2::monster(zombie); 0.2::monster(headless_horseman); 0.2::monster(vampire) :- monster_location(nearby_farm). adventure :- monster_location(X), monster(Y), adventure_start. any_monster_location :- monster_location(X). any_monster :- monster(X). two_locations :- monster_location(X), monster_location(Y), X \\== Y. two_monsters :- monster(X), monster(Y), X \\== Y. vampire_after_flat_tire :- monster(vampire), flat_tire. % Queries:. query(adventure_start). query(any_monster_location). query(any_monster). query(adventure). query(two_locations). query(two_monsters). query(monster(ghost)). query(vampire_after_flat_tire).  In this example we also show a number of interesting facts that we might want to be able to query. The probability that an adventure starts is 0.832. Given that the probability for a monster location and a monster existing is 1 in both cases, and adventure requires only an \u0026ldquo;adventure start\u0026rdquo;, a \u0026ldquo;monster\u0026rdquo; and its \u0026ldquo;location\u0026rdquo;, the probability for an adventure happening is also 0.832. As mentioned before, due to the annotated disjunctions the probability of having two monsters or two locations is 0. We can also query for facts such as the probability of a monster occuring, which is inferred based on both the conditional probability given the monster location and the probability of the monster location itself. For example the probability of the monster being a ghost is 0.37. Finally we can calculate the probabilities for any particular scenario that we create, such as the probability of having the monster be a vampire after having a flat tire: 0.064.\nAs one can see many spooky scenarios can be explored with ProbLog. Here we only taken a quick peek for representing a small portion of Scooby Doo stories, but these can also be applied to other domains, be it reasoning in the legal, financial, health and other fields. So do not be scared off and give it a try for any domain modelling you might encounter involving probabilities!\n","date":1575586800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586800,"objectID":"de2b4fba4369755384e4f7182b6b89c5","permalink":"https://www.newresalhaider.com/post/probable-mystery-machine/","publishdate":"2019-12-06T00:00:00+01:00","relpermalink":"/post/probable-mystery-machine/","section":"post","summary":"Solving the mysteries of Scooby Doo with probabilistic logic programming.\n","tags":["AI","Prolog","probabilistic programming","ProbLog"],"title":"The Probable Mystery Machine","type":"post"},{"authors":["Newres Al Haider","Dilhan Thilakarathne","Joost Bosman"],"categories":null,"content":"","date":1568160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568160000,"objectID":"78963eca4a51022c0d5824fe51f99f5a","permalink":"https://www.newresalhaider.com/publication/solving-compliance-software-contracts/","publishdate":"2019-09-11T00:00:00Z","relpermalink":"/publication/solving-compliance-software-contracts/","section":"publication","summary":"Ensuring compliance with various laws and regulations is of utmost priority for financial institutions. Traditional methods in this area have been shown to be inefficient. Manual processing does not scale well. Automated efforts are hindered due to the lack of formalization of domain knowledge and problems of integrating such knowledge into software systems. In this work we propose an approach to tackle these issues by encoding them into software contracts using a Controlled Natural Language. In particular, we encode a portion of the Money Market Statistical Reporting (MMSR) regulations into contracts specified by the clojure.spec framework. We show how various features of a contract framework, in particular clojure.spec, can help to tackle issues that occur when dealing with compliance: validation with explanations and test data generation. We benchmark our proposed solution and show that this approach can effectively solve compliance issues in this particular use case.","tags":null,"title":"Solving Financial Regulatory Compliance Using Software Contracts","type":"publication"},{"authors":null,"categories":null,"content":"This article is the fifth part of a series, examining the use of the Clojure language for representing Linked Data, using examples from Aesop\u0026rsquo;s stories. The topic of this article is to explain the somewhat contentious subject of blank nodes.\nOne of the strengths of RDF as a graph representation format is the way resources are named. Through the use of Uniform Resource Identifiers (URIs) every element of the graph can be uniquely identified. With such generic and powerful facilities for naming it can easily represent information in any domain. For example on schema.org elements have been defined for the notion of a medical condition (http://schema.org/MedicalCondition), employee (http://schema.org/employee) and bank account (http://schema.org/BankAccount), just to name a few. In particular the namespacing part of the URI, e.g.: http://schema.org/ for http://schema.org/employee , helps to ensure that concepts can be uniquely named, even in scenarios with multiple definitions of the same concept.\nBlank nodes go against this notion of making everything explicitly named. In fact an alternative name for a blank node is \u0026ldquo;an anonymous resource\u0026rdquo;\u0026ldquo;. Instead of giving a resource an explicit name with a URI a placeholder is used. This indicates the existence of the resource, but does not tie it together with a namespaced name. In the Turtle syntax for RDF we can use a label prefixed by _: to indicate a blank node. For example, the following RDF graph states that the fox and the stork both give out an invitation.\n@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . \u0026lt;#fox\u0026gt; \u0026lt;#gives-invitation\u0026gt; _:invitation1. \u0026lt;#stork\u0026gt; \u0026lt;#gives-invitation\u0026gt; _:invitation2.  Due to the invitations having different names we can expect them to be different resources. However the exact names of these resources do not matter. For example the RDF triples below have arguably the same meaning:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . \u0026lt;#fox\u0026gt; \u0026lt;#gives-invitation\u0026gt; _:abc. \u0026lt;#stork\u0026gt; \u0026lt;#gives-invitation\u0026gt; _:xyz.  It is important to reiterate that the blank nodes are not resource identifiers such as URIs. They are also only local in scope: an _:invitation1 in one graph and a _:invitation1 in another are not referring to the same thing. Even resources used in the similar places in different graphs are not the same. For example the _:abc and the _:invitation1 used in the above graphs, while expressing the same meaning, are not the same resource.\nThe above features are both the strength and the weakness of using anonymous resources. We are not required to use a specific named identifier, but this makes referring to resources and comparing them more difficult.\nThere are number of scenarios where such anonymous resources can be useful. For example, when representing complex structures not easily expressed in triples where we would need \u0026ldquo;placeholder nodes\u0026rdquo; in the graph but do not particularly care about its naming. In other cases we want to hide some information, and blank nodes could be used as placeholders for named resources. A good overview of the various uses of Blank Nodes can be found in the paper: On Blank Nodes.\nWith the above description of blank nodes, we also want to provide something similar in our Clojure based RDF representation as well. As we are using keywords to represent URIs in our Clojure representation (i.e. :fox and :rdf/type), a natural element to differentiate them is to use symbols for blank nodes. Symbols are created in Clojure by prefixing it with '. For example in the Clojure based RDF representation we use blank nodes for representing invitations:\n(def fox-and-stork-blank-node-edn {::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot;} ::aes/facts #{[:fox :rdf/type :animal] [:stork :rdf/type :animal] [:fox :gives-invitation 'invitation1] ['invitation1 :has-invited :stork] ['invitation1 :has-food :soup] ['invitation1 :serves-using :shallow-plate] [:stork :gives-invitation 'invitation2] ['invitation2 :has-invited :fox] ['invitation2 :has-food :crumbled-food] ['invitation2 :serves-using :narrow-mouthed-jug] [:fox :can-eat-food-served-using :shallow-plate] [:fox :can-not-eat-food-served-using :narrow-mouthed-jug] [:stork :can-eat-food-served-using :narrow-mouthed-jug] [:stork :can-not-eat-food-served-using :shallow-plate]}})  The above is our version of \u0026ldquo;The Fox and the Stork\u0026rdquo; story that we previously explored in this series of articles The main difference is that two blank nodes are used: 'invitation1 and 'invitation2, instead of named resources. Perhaps the story teller might want to hide some details of their invitations.\nAs with all the previous features in this series of articles, blank nodes been implemented in our implementation of this syntax in the Aesopica library for using Clojure to write Linked Data. Hiding details with blank nodes, even in Clojure, is now just one library away.\n","date":1559944800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570312800,"objectID":"bf5c418fabea5d54d5b55a0dca261d3a","permalink":"https://www.newresalhaider.com/post/aesopica-5/","publishdate":"2019-06-08T00:00:00+02:00","relpermalink":"/post/aesopica-5/","section":"post","summary":"A way to represent Linked Data using Clojure, with an example based on Aesop's stories, Part 5: Blank Nodes.\n","tags":["Clojure","Linked Data","RDF","Semantic Web","knowledge representation","knowledge graph","Aesopica"],"title":"Aesopica, Part 5: Blank Nodes","type":"post"},{"authors":null,"categories":null,"content":" Deep Learning is a field within Artificial Intelligence (AI) that has got quite a lot of attention lately, due to some truly impressive results in recent years. From recognizing objects in images with accuracy that rivals humans, to generating realistic looking texts, to even beating professional players in Starcraft 2, some truly groundbreaking applications are done with Deep Learning techniques.\nAs someone whose AI background is more Symbolic Artifical Intelligence, but is anxious to learn, it is a good time as any to explore this field. Thankfully there are some excellent books and tutorials out there to get a nice start.\nOne book that has caught my attention is Dive into Deep Learning, which seems to have a nice overview of the field, while being very practical at the same time. I aim to work through the book and share my notes, summaries and experiences on this journey in a series of articles. My goal is to write these articles for a bit more broader audience than the book itself. I hope that even those with less exposure to the field than me could follow along, and if a topic piques their interest, they can use the book for a more detailed reference point.\nThe first chapter that I aim to go over is the introduction to the book as well as Machine Learning in general. As Deep Learning (DL), is a form of Machine Learning (ML), an intro/refresher on the topic of Machine Learning is a natural start.\nWhat is Machine Learning? In most scenarios, programs are written in way where the programmer gives precise information about the problem and/or how to solve it. For example in imperative programming the program is essentially a list of statements that command the computer what to do. Even in the many forms of declarative programming, such as functional- or logic programming, providing the solution is done by explicit descriptions by the coder. The coder would describe the entirety of the problem with mathematical functions or with logical axioms respectively.\nHowever there are scenarios where such paradigms are not adequate. Take for example a case where we where have set of photos of cats and dogs. Suppose we want need to write a program that, given a photo, can recognize the species and breed of the animal depicted. Generally it is difficult to even begin formulating such a problem in terms of the usual programming paradigms. Usually any handwritten solution we can come up with will be very brittle: it will often fail to recognize the right kind of pet from the photo, or it would only be correct for a very limited set of photos.\nAn alternative way to solve this problem is by letting the computer learn what kind of pet is in the photo. The computer can use a set of labelled examples where the kind of animal and breed is already known and given alongside the photo. In such cases we start with an initial, perhaps even random, model that can make this prediction. Such a model will likely be pretty bad at the start, otherwise the problem would already be solved. Then we use the labelled data to update this model. The hope is that the new model will be better at classifying animals. The intention is to keep adding data and improving the model until we decide that our model is good enough to solve our pet classification problem.\nThis learning from previous experiences by the machine to solve a problem is denoted as machine learning.\n  The recognition of dogs and cats, along with their breeds, is actually an interesting research problem in machine learning. This is due to the subtle differences between breeds making the problem difficult for computers. These images are from the The Oxford-IIIT Pet Dataset that can be used to help evaluate techniques aiming to tackle this issue. The images of this dataset are licensed under Creative Commons Attribution-ShareAlike 4.0 International License. Copyright of the images is with their original owner.   There are a large number of forms of machine learning, of which deep learning is only a particular branch, but there are common elements among the various techniques.\nElements of Machine Learning Data Data is the example information from which the machine learning aims to learn. In the previous scenario, the data is the labelled photos of pets.\nModel The model designates the whole process of using the data and transforming it into the goal of machine learning. In our example the model would be the full process that can take a given photo and transform it into a prediction of the pet depicted.\nObjective Function The objective function denotes how good, or bad, our model currently is. As mentioned before, the reason we perform machine learning is that we aim to let the computer learn how to solve a problem. The objective function allow us to measure the quality of our current solution, so it can be assessed whether the machine learning is progressing towards an acceptable solution.\nOptimization Algorithm The optimization algorithm that describes the process of moving from one model to a better one. This allows for the learning to happen by moving from one model to a one that better solves the problem.\nKinds of Machine Learning Machine learning is a large field with a wide variety of techniques and potential problems to solve. Generally techniques are differentiated by the data they input and output, as well as the specific type of problem they target.\nSupervised Learning Supervised learning aims to predict targets given some input data. A good example of this is our previous scenario where we were trying to predict what type of pet is in a photo. If we have a number of photos for which we know what kind of animal is depicted in them (i.e. labeled data), we could perform such supervised learning.\nVarious kinds of supervised learning can be further subdivided based on what kind of target we aim to predict. Some common types of supervised learning are:\nClassification The above example is actually called a classification scenario. In general, classification problems are those where given an example, we aim to find to what particular class that example belongs to. While in the example we described the classes as the species and the breeds of pets, many other types of classes can be used depending on the problem we aim to solve.\nTagging Consider a scenario where there could be more than one pet in the photo and we want to recognize each of them. Predicting in such cases is called tagging. The main difference between classification and tagging, is that with tagging multiple classes need to be recognized at once (e.g.: the photo can have both a dog and a cat ). This in contrast with classification, where the classes are exclusive (e.g.: dog or a cat).\nRegression The case where we want to predict a (real valued) number, for example the weight of the pet depicted in the photo, is called a regression.\nSearch and Ranking Search and ranking is a scenario where we want to figure out an order between various items. For example suppose that we want to figure out popularity rankings between various breeds of dogs and cats.\nUnsupervised Learning In cases with supervised learning, a set of examples for which the result is already known must be available. Often large quantities of such information is required to get accurate results. However such information can be scarce, or simply unavailable.\nEven in such cases there is a wealth of information that can still be learned from the data through machine learning. Some example techniques include:\nClustering With the absence of clearly labelled categories given to us, we can still want to group the data into categories. This process is called clustering. For example suppose we have a set of photos depicting all sort of pets, without any labels. Here we could still aim to group similar pets into clusters.\nData Generation/Synthesis Given a set of data, we can also aim to synthesize data that is similar to the given data. For example if we have a large set of dog photos we can also aim to generate a photo of a, non-existent, dog.\nReinforcement Learning The final group of machine learning techniques that we go over in this article are those where the learning process is interacting with the environment. In reinforcement learning the main goal is to figure out what kind of action needs to be taken in a particular situation. As an example, take a scenario where you want to teach a robot dog to play football.\nThere process of reinforcement learning is as follows. The agent interacts with the environment through actions and observes the environment reacting to those actions. Based on the environment the agent may get rewards, either positive or negative. The rewards, together with the observations, guide the selection of subsequent actions. There is a cycle of actions, leading to observations and potentially rewards, and then again to actions. This cycle can then be repeated possibly indefinitely or until some goal is reached.\nTo make this description a bit more concrete, lets take our example scenario of letting a robot dog learn football. Here the agent is the decision making process of the robot dog. The environment itself is a playing field with other robots and a ball. The observations are the sensor data of this environment, such as the vision of the robot. Rewards could be given for taking control of the ball, making a successful pass and of course scoring. Negative rewards can be given for the robot missing a pass, walking off field and other undesirable actions.\n  Teaching four legged robots, such as the AIBO robot dogs, to play football is one of the leagues that is part of the RoboCup competition aimed at promoting robotics and AI research. This photo depicts the team in a four-legged league game from RoboCup 2006 in Breman, Germany. Public Domain Photo by Brad Hall   Reinforcement learning as a whole can be pretty complex with lots of variables based on can be known about the environment, state or actions. Subcategories of reinforcement are generally based on the given restrictions with these variables.\nTowards Deep Learning The above is a general introduction to machine learning, so the question arises how deep learning fits into the picture. Machine learning as a field has quite a bit of history with many of its techniques being laid out in the previous century. A number of such techniques, such as Neural Networks initially showed great promise but research and applications on them were languishing due to the lack data and large amount of processing power to enable such techniques. In recent years this has changed, alongside with some important advances, that led to deep learning techniques being one of the most effective approaches for various machine learning applications.\nIn addition the availability of frameworks for deep learning, such as MXNet, which we will use in our learning process, means that the field is very inviting for new users and applications.\nConclusion This was a quick rundown of the first chapter. The book actually goes into much more detail, with some previews of techniques and extensive references, for the interested reader. If you have any remarks or suggestions for this series of articles please let me know! I am quite anxious for the next part when I hope to plunge deep into some coding with MXNet.\n","date":1549234800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549234800,"objectID":"c01ba075c76c8fe9fb446a85bfc91978","permalink":"https://www.newresalhaider.com/post/exploring-the-deep-1/","publishdate":"2019-02-04T00:00:00+01:00","relpermalink":"/post/exploring-the-deep-1/","section":"post","summary":"Diving into Deep Learning Part 1: An Introduction to Machine Learning\n","tags":["AI","machine learning","deep learning"],"title":"Exploring the Deep, Part 1: Introduction","type":"post"},{"authors":null,"categories":null,"content":"The use of logic is a common element in Science Fiction. In the Star Trek universe Vulcans are a species that is famously known for aiming to live by logic and reason. Because of this they are often considered masters of these subjects. Yet there was a case in an episode of the Star Trek show Deep Space 9, where Quark, a Ferengi, was able to convince Sakonna, a Vulcan, of the error of her logic and reasoning.\nFor this Quark made use of Ferengi philosophy, namely the Third Rule of Acquisition. The Rules of Acquisition are a series of proverbs and guidelines that govern Ferengi society, and notably their business dealings that take a prominent place in their lives. The Third Rule of Acquisition states that \u0026ldquo;Never spend more for an acquisition than you have to.\u0026rdquo; By applying this rule to the situation in the episode Quark was able make it clear to Sakonna that the best time broker a peace agreement would be \u0026ldquo;right now\u0026rdquo;, as the price of peace is at an all time low.\n Quark explaining the Third Rule of Acquisition to Sakonna  Copyright CBS Corporation   Much like with Ferengi society, various rules and regulations play a prominent role in our lives and dealings with each other. So much so, that navigating the various rules to their logical conclusion, whether in the realm of law, finance and other domains, is often a difficult process. Thankfully there are tools and techniques to help us. The programming language Prolog, in particular, can be a very helpful in dealing with various rules and logical problems. This article aims to provide a brief introduction to this language using by using it to show how Quark\u0026rsquo;s reasoning can be implemented within a computer program.\nProlog is a logic programming language, originally created in the 1970s, but with many modern implementations such as SWI-Prolog. With logic programming programs are written and solved using some variation of a formal logic. Using such logic, information about the problem and its domain is first declared. Then the user can pose queries about the problem domain, which the programming language aims to answer through reasoning with the available information. This style of programming contrasts with the more common, imperative, paradigm. Instead of telling the computer how to solve the problem, we can declare information about the problem and let the computer, through the use of logic, solve it for us.\nIn order to show how Prolog works, we aim to use it to represent the same problem and reasoning that Quark used to convince Sakonna. To do this first lets examine the situation depicted the episode a bit more closely. In the episode the Maquis are a group that are at odds Cardassian colonists both living the Demilitarized Zone. Tensions were escalating as the Cardassian colonists were recently supplied in secret with weapons by the Cardassian Union. As a result Sakonna, along with other members of the Maquis, aimed at acquiring more weapons of their own. Even after it was found that the Cardassian Union was behind weapon supplies, Sakonna still aimed at gathering more, as a way to ensure peace. Quark pointed out the flaws in the logic of her argument, given the Third Rule of Acquisition: \u0026ldquo;Never spend more for an acquisition than you have to.\u0026rdquo; If the goal of Sakonna is truly to acquire peace, than it is the perfect time to be negotiating with the Cardassian colonists. With the flow of the smuggled in weapons having stopped, and both sides already having weapons, neither the Maquis nor the Cardassian colonists have any advantage. By aiming to acquire weapons still, they would only escalate the conflict, and making peace more costly in the long run.\nTo express this scenario with Prolog, we are going to introduce some elements of this language first (for a bit more through introduction see the excellent Learn Prolog Now! available online). There are three basic elements to a Prolog program: facts, rules and queries.\nFacts are elements that have been stated to hold. For example the following statement:\nadvantage(cardassians).  can be used to denote that the advantage is held by the Cardassians colonists.\nRules are a way for Prolog to infer new information from the knowledge that already exists. For example if we aim to state that \u0026ldquo;if the Cardassian colonists have the advantage the price of peace is high\u0026rdquo; in Prolog we would have the rule:\npriceOfPeace(high) :- advantage(cardassians).  There are two parts to writing such rules in Prolog: the body and the head. The body of the rule is in this case advantage(cardassians) while the head is priceOfPeace(high). In Prolog if the body of the rule holds true, than it can be concluded that the head is true as well. This exactly matches to what we aim to express: if the Prolog program knows that the Cardassian colonists hold the advantage, than it can conclude that the price of peace is high.\nFacts and rules together form the knowledge base that can describe a domain. In this case the domain is the situation between the Cardassian colonists and the Maquis. The final piece, queries, allows us to examine this knowledge base and ask questions on what Prolog can infer from this knowledge. For the above example we could query whether the price of peace is indeed high, which should follow directly from the semantics of the rules and facts that we have described.\nGiven that we load in the knowledge base consisting of the above-mentioned fact and rule, the query:\n?- priceOfPeace(high).  that asks whether the price of peace is high, will return true indicating that this is indeed the case. Instead if we ask whether the price of peace is low, using the query:\n?- priceOfPeace(low).  the result will be false indicating this is not the case.\nWe can also ask more open ended questions using variables. Variables are written by starting with a capitalized letter (or an underscore), such as X. These variables could be used to write queries with unknowns. The query:\n?- priceOfPeace(X).  will give us the result:\nX = high  Which again is what would directly follow from the facts and the rules. What Prolog does with variables is to try to \u0026ldquo;unify\u0026rdquo; them with known values that match (or other variables). In this case from the knowledge base we have given it, it unifies it with the value of high.\nFrom the basic elements of facts, rules and queries Prolog is able to represent and answer problems in many domains. This is also shows off the feature of a logical programming language, such as Prolog, that make it different compared to many other programming languages. Instead of telling the program what to do, the program becomes a description of the domain, over which queries are answered to solve the overall goal.\nBeyond the above basics, Prolog has many features to support the description of more complicated domains. Here we only list a few that helps us to convey our translation of Quark\u0026rsquo;s reasoning into Prolog.\nOne such feature is the use variables within the rules themselves. The rule\nacquirePeace(X) :- priceOfPeace(X).  indicates that the price of acquiring peace depends on the price of peace.\nThe rule\npriceOfPeace(low) :- advantage(cardassians), advantage(maquis).  shows off the logical operator and, meaning that the price of peace is low if both the Cardassians and the Maquis have the advantage.\nThe rule\npriceOfPeace(low) :- \\+ advantage(cardassians), \\+ advantage(maquis).  shows off the logical not, denoted by the \u0026lsquo;+\u0026rsquo; symbol, which states that the price of peace is also low if neither the Cardassians nor the Maquis have the advantage.\nFinally, much like in other languages, comments for the code can also be written. This is done by prefacing a line with \u0026ldquo;%%\u0026rdquo;.\nNow if we put every element together to use Prolog to describe Quarks scenario, a possible knowledge base is as follows:\n%% Rules acquirePeace(X) :- priceOfPeace(X). priceOfPeace(low) :- \\+ advantage(cardassians), \\+ advantage(maquis). priceOfPeace(low) :- advantage(cardassians), advantage(maquis). priceOfPeace(high) :- advantage(cardassians). priceOfPeace(low) :- advantage(maquis). advantage(cardassians) :- weapons(cardassians), \\+ weapons(maquis). advantage(maquis) :- \\+ weapons(cardassians), weapons(maquis). %% Facts weapons(cardassians). weapons(maquis).  In the overall knowledge base, the logic of Quark\u0026rsquo;s reasoning is broken down into a number of rules and a pair of facts.\nThe rules state that advantage of either side, the Cardassians settlers or the Maquis, is decided by one side having weapons while the other side has not. The price of peace is in turn dependent on who has the advantage. In this formalisation the price of peace is only high if Cardassians have the advantage. Finally the price of acquiring peace is dependent solely on the price of peace.\nThe facts for this scenario is that both the Cardassian settlers and the Maquis have weapons.\nWith this knowledge base describing Quark\u0026rsquo;s reasoning process the query to see for what price we can aquire peace:\n?- acquirePeace(X).  will indeed return\nX = low  indicating that acquiring peace can be done at a low price.\nGoing a bit beyond this query, if we would further want to test the logic of Quark\u0026rsquo;s scenario, we can also inquire about other information.\nFor example if we would ask for the price of peace:\n?- priceOfPeace(X).  we would also unsurprisingly get\nX = low  as with the rules defined in our knowledge base these values are intertwined.\nWe can also ask for who has the advantage:\n?- advantage(X).  which will return:\nfalse.  which is completely in line with the scenario that noone has the advantage.\nWe can also ask who has weapons, the query of:\n?- weapons(X).  gives us the answer\nX = cardassians  \u0026hellip; but wait, this can not be right! Did we not state in the knowledge base that both the Cardassian colonists and the Maquis have weapons? Prolog can actually return mutliple answers, if they exist. In SWI-Prolog this can be done by pressing semicolon (;) after an answer, in which case another answers is returned, if it exists or simply false otherwise. By pressing ; once after the first answer we will see a total output such as:\nX = cardassians ; X = maquis.  Hopefully Sakonna would also be quite convinced with the logic of Prolog, but just to be absolutely sure, lets examine some scenario\u0026rsquo;s where the facts of the scenario are changed. In such cases the rules should still be applied in ways that we would expect.\nSuppose that our only fact now is that only the cardassians colonists have weapons, while rules remain the same. Giving the query for knowing the price of acquiring peace:\n?- acquirePeace(X).  will now return:\nX = high  Hopefully, much like Quark\u0026rsquo;s application of the Third Rule of Acquisition, this intro would have been enough to convince Sakonna of the logic of purchasing peace at the lowest possible price. Similarly, I hope that as a reader, this article gave some insight to the usefulness of Prolog in such scenarios. Next time, you are dealing with a problem domain, that would easily match to a similar scenario of rules, facts and queries, give Prolog a try. It is, after all, a very logical choice.\n","date":1548975600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549234800,"objectID":"4dc7525de5039a887ca8cbb24329d836","permalink":"https://www.newresalhaider.com/post/prolog-price-of-peace/","publishdate":"2019-02-01T00:00:00+01:00","relpermalink":"/post/prolog-price-of-peace/","section":"post","summary":"Introducing the Prolog programming language through Quark's explanation for using the Third Rule of Acquisition to acquire peace at the lowest price. \n","tags":["reasoning","rules","knowledge representation","Prolog","law","RegTech","Star Trek","Deep Space 9"],"title":"Prolog and the Price of Peace","type":"post"},{"authors":null,"categories":null,"content":"This article is the fourth part of a series, examining the use of the Clojure language for representing Linked Data, with examples from Aesop\u0026rsquo;s stories. The topic of this article is to describe how to do some basic conversions from our Clojure representation of Linked Data, to some of the other formats, such as Turtle, NQUADS or JSON-LD.\nIn previous articles of this series, we created a Clojure based syntax for defining Linked Data. In order to make this syntax a viable member of the Linked Data ecosystem, it is important to provide conversion functionality to other Linked Data formats. This allows for the user of the associated Aesopica library, to create and use Linked Data in a Clojure based environment, and convert it, when needed, to other formats. In order to implement this functionality we made use of Clojure\u0026rsquo;s Java interop and the Apache Jena, and made it available in the Aesopica library.\nTo start off we begin with the basic example of \u0026ldquo;The Fox and The Stork\u0026rdquo; story that we introduced initially. The Clojure representation of this is as follows:\n(def fox-and-stork-edn {::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot;} ::aes/facts #{[:fox :rdf/type :animal] [:stork :rdf/type :animal] [:fox :gives-invitation :invitation1] [:invitation1 :has-invited :stork] [:invitation1 :has-food :soup] [:invitation1 :serves-using :shallow-plate] [:stork :gives-invitation :invitation2] [:invitation2 :has-invited :fox] [:invitation2 :has-food :crumbled-food] [:invitation2 :serves-using :narrow-mouthed-jug] [:fox :can-eat-food-served-using :shallow-plate] [:fox :can-not-eat-food-served-using :narrow-mouthed-jug] [:stork :can-eat-food-served-using :narrow-mouthed-jug] [:stork :can-not-eat-food-served-using :shallow-plate]}})  The full details of this representation are explained in our previous work. Here we only briefly summarize its main elements. The above mentioned example defines a knowledge base containing a set of facts that describe the \u0026ldquo;The Fox and The Stork\u0026rdquo; story. Each fact is a triple of a subject, predicate and object. These elements are all represented by an URI, but for human readability and use as well as ease of use in Clojure, they are identified by (namespaced) keywords. The context map, containing the keywords for the namespaces used, allows us to transform the namespaced keywords into full URIs when required. Of course there are more elements possible in Linked Data/RDF and in this representation as well, such as literal values, but this summary should suffice for this article.\nNow in order to explain how this conversion is done, assuming no familiarity with Clojure or a similar language, two new concepts are required.\nFirst, it is important to note that in the above example we bind the \u0026ldquo;The Fox and The Stork\u0026rdquo;, Linked Data representation to the fox-and-stork-edn variable. Although this is not a necessity for creating the knowledge base, it allows us to reuse this definition from inside the code and in this article as well, without explicitly writing out the full representation each time.\nThe second concept that we make use is how Clojure functions are called to be executed. In Clojure invoking a function has the general form of (function-name param1 param2 ...). For example lets assume that the function for translation from our Clojure representation to Turtle is represented by conv/convert-to-turtle. Here conv is a shorthand for Aesopica\u0026rsquo;s conversion namespace. Given this, the call to translate to a Turtle string representation of the Linked Data can be invoked by:\n(conv/convert-to-turtle fox-and-stork-edn)  The resulting string representation shows the same Linked Data knowledge base in Turtle syntax:\n\u0026quot;@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . \u0026lt;fox\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;stork\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;gives-invitation\u0026gt; \u0026lt;invitation1\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;has-invited\u0026gt; \u0026lt;stork\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;has-food\u0026gt; \u0026lt;soup\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;serves-using\u0026gt; \u0026lt;shallow-plate\u0026gt;. \u0026lt;stork\u0026gt; \u0026lt;gives-invitation\u0026gt; \u0026lt;invitation2\u0026gt;. \u0026lt;invitation2\u0026gt; \u0026lt;has-invited\u0026gt; \u0026lt;fox\u0026gt;. \u0026lt;invitation2\u0026gt; \u0026lt;has-food\u0026gt; \u0026lt;crumbled-food\u0026gt;. \u0026lt;invitation2\u0026gt; \u0026lt;serves-using\u0026gt; \u0026lt;narrow-mouthed-jug\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;can-eat-food-served-using\u0026gt; \u0026lt;shallow-plate\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;can-not-eat-food-served-using\u0026gt; \u0026lt;narrow-mouthed-jug\u0026gt;. \u0026lt;stork\u0026gt; \u0026lt;can-eat-food-served-using\u0026gt; \u0026lt;narrow-mouthed-jug\u0026gt;. \u0026lt;stork\u0026gt; \u0026lt;can-not-eat-food-served-using\u0026gt; \u0026lt;shallow-plate\u0026gt;.\u0026quot;  This representation has a similar form to our Clojure based notation. A set of facts is represented and prefixes and/or a base prefix is used, to enable easy reading and writing of the triples.\nNow let us look at some other formats and conversions.\nTriG is an extension of the Turtle format for enabling \u0026ldquo;named graphs\u0026rdquo;. Now this is a topic of a previous article but here it is suffice to say that by associating a set of facts with a specific graph, we enable the easy adding of metadata to these facts. To show this conversion, we use an example that uses this notion:\n(def fox-and-stork-named-graph-edn {::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot; :time \u0026quot;http://www.w3.org/2006/time#\u0026quot;} ::aes/facts #{[:fox :rdf/type :animal] [:stork :rdf/type :animal] [:fox :gives-invitation :invitation1 :dinner1] [:invitation1 :has-invited :stork :dinner1] [:invitation1 :has-food :soup :dinner1] [:invitation1 :serves-using :shallow-plate :dinner1] [:stork :gives-invitation :invitation2 :dinner2] [:invitation2 :has-invited :fox :dinner2] [:invitation2 :has-food :crumbled-food :dinner2] [:invitation2 :serves-using :narrow-mouthed-jug :dinner2] [:invitation1 :serves-using :narrow-mouthed-jug :dinner2] [:dinner1 :time/before :dinner2]}})  As one can see, here we simply extend our triple based representation of facts to include either triples or quads. In a quad the last element is the graph name identifier of the graph the fact is a member of.\nTranslating this representation to TriG can be done by:\n(conv/convert-to-trig fox-and-stork-named-graph-edn)  Which results in the following string representation that is TriG formatted:\n{ \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; \u0026lt;http://www.w3.org/2006/time#before\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026gt; . } \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; { \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026gt; ; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/crumbled-food\u0026gt; ; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026gt; . } \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; { \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/soup\u0026gt; ; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/shallow-plate\u0026gt; ; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; . }  There are a number of differences in representation from the above TriG output to he Clojure representation, but also from the previous Turtle output. Probably one of the most apparent is that in this output no prefixes are used: URIs are all written out fully. Both Turtle and TriG are flexible in whether they abbreviate URIs with prefixes or not. This is completely left up to the author, on in this case the specific way the conversion has been implemented. Another difference is how graphs are identified. Instead of using a quad like formatting for denoting the graph to which each fact belongs to they are grouped together. For example in the form of: \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; { ... }, all the facts inside the curly braces belong to the \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; graph. Finally a somewhat similar construction is used to abbreviate a group of triples that all use the same object. Instead of writing each fact out fully, \u0026ldquo;predicate-lists\u0026rdquo; are used to match a single subject with a series subject and object pairs. This is quite a nice feature, and something similar is definitely on the list of future improvements to the Clojure notation, although care must be taken that such shorthands can make the definition a bit more complex.\nSpeaking of complexity, an interesting format created with the purpose of being very simple is NQUADS. This is a straightfoward, line based syntax where each fact is represented by a single line. It is actually an extension of the N-Triples format, with support added for handling named graphs. The conversion of our named graph example using the function invocation:\n(conv/convert-to-nquads fox-and-stork-named-graph-edn)  would give us the following example:\n\u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; \u0026lt;http://www.w3.org/2006/time#before\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/crumbled-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/soup\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/shallow-plate\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; .  As one can see this format does not use prefixes: each fact is a triple or a quad on a single line ending with a dot, with each element URI written out fully. This way of writing facts is similar to the Clojure based notation, with main change that the Clojure notation does use prefixes for URI abbreviation. This simplicity contrasts with the flexibility of the Turtle format, which can be more terse, but more complex to parse and generate. This also shows that a separate N-Triples converter is not really needed. As long as the original knowledge bases does not use any named-graphs the result will be the same as with N-Triples.\nThe final format that we aim to convert to is JSON-LD. This is a format based on the JavaScript Object Notation JSON, which allows for very easy interoperability with JSON based tools.\nConverting can be done with the following invocation:\n(conv/convert-to-json-ld fox-and-stork-named-graph-edn)  resulting in the following JSON representation:\n{ \u0026quot;@graph\u0026quot; : [ { \u0026quot;@graph\u0026quot; : [ { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026quot;, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026quot; } }, { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026quot;, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/soup\u0026quot; }, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026quot; }, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/shallow-plate\u0026quot; } } ], \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026quot;, \u0026quot;http://www.w3.org/2006/time#before\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026quot; } }, { \u0026quot;@graph\u0026quot; : [ { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026quot;, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026quot; } }, { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026quot;, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/crumbled-food\u0026quot; }, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026quot; }, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026quot; } }, { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026quot;, \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026quot; : { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026quot; } } ], \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026quot; }, { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026quot;, \u0026quot;@type\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026quot; }, { \u0026quot;@id\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026quot;, \u0026quot;@type\u0026quot; : \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026quot; } ] }  The biggest benefit of this format is the compatibility with JSON based tools and techniques. Regular JSON parsers, encoders and other tooling will just work, giving the format a very wide reach. Similarly to this our Clojure based approach uses EDN as its basis. This is a subset of Clojure, notably its notation of data values, and is used by Datomic and others as a data transfer format.\nTo summarize, we have seen how converting Linked Data from the Clojure representation to various other formats using the Aesopica library is just a function invocation away. We have also looked at some of the differences between various syntaxes, notably the benefits that they provide: Turtle/TriG offers a lot of flexibity and shorthands for reading and writing, N-Quads simplicity of notation, and JSON-LD compatibility with an existing and well used standard. The Clojure representation is aimed creating a new, and hopefully interesting blend. It makes use of prefixes for easy reading and writing by human users, similarly to what is possible in Turtle. It has the simplicity of fact representation as triples and quads, like in N-Quads. Finally it uses a common, albeit not nearly as widespread, standard a basis so it can make use of EDN based tooling.\nOne interesting element, that the Turtle and Trig formats provide, is various short-hands for reading and writing. We believe this is a very useful feature, but of course the trade-offs of the shorthands versus the simplicity of notation must be taken into account. The format of which such shorthand will take shape, is therefor the topic for another article.\nNote that previous articles in this series can be also be found on this site:\n Part 1, General Introduction covers the basic elements of Linked Data/RDF along with their representation in Clojure. It also introduces \u0026ldquo;The Fox and the Stork\u0026rdquo; formalised using Linked Data. Part 2, Literal Values describes how literal values can be represented. Part 3, Named Graphs describes the notion of representing, and naming, graphs, which allows for representing information about facts and graphs themselves.  As always, the functionality detailed in these articles can be found in the Aesopica library for using Clojure to write Linked Data.\n","date":1545087600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545087600,"objectID":"916aa4d049119ad6b5298898aaf8ee28","permalink":"https://www.newresalhaider.com/post/aesopica-4/","publishdate":"2018-12-18T00:00:00+01:00","relpermalink":"/post/aesopica-4/","section":"post","summary":"A way to represent Linked Data using Clojure, with an example based on Aesop's stories, Part 4: Basic Conversion to Other Formats.\n","tags":["Clojure","Linked Data","RDF","Semantic Web","knowledge representation","knowledge graph","Aesopica"],"title":"Aesopica, Part 4: Basic Conversion to Other Formats","type":"post"},{"authors":null,"categories":null,"content":"This article is the third part of a series, examining the use of the Clojure language for representing Linked Data, with examples from Aesop\u0026rsquo;s stories. In part one the basic elements of \u0026ldquo;The Fox and the Stork\u0026rdquo; story were formalised as Linked Data in Clojure, while in part two we investigated how various literal values can be described. In this article we examine how information about facts themselves, such as meta-information, can be described with Linked Data. As always, the functionality detailed in these articles can be found in the Aesopica library for using Clojure to write Linked Data.\nIn Linked Data, facts are represented as triples of subjects, predicates and objects. For example, when representing the story of the \u0026ldquo;The Fox and the Stork\u0026rdquo; one fact that we want to represent is \u0026ldquo;The Fox gives an invitation.\u0026rdquo; In this fact \u0026ldquo;The Fox\u0026rdquo; is the subject, the \u0026ldquo;gives an\u0026rdquo; is the predicate and \u0026ldquo;an invitation\u0026rdquo; is the object. Of course, as we mentioned in our previous articles, one of the strengths of Linked Data is that the elements are more precisely defined than just their natural language representations in a sentence. A Uniform Resource Identifier (URI) is used to more formally identify these elements. This would make the previous fact to be written as follows, using the Turtle notation of RDF:\nhttp://www.newresalhaider.com/ontologies/aesop/foxstork/fox http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1.  When making using a base prefix for http://www.newresalhaider.com/ontologies/aesop/foxstork/fox this could be shortened as:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . \u0026lt;fox\u0026gt; \u0026lt;gives-invitation\u0026gt; \u0026lt;invitation1\u0026gt;.  Using our Clojure based notation, that was introduced in the previous articles, we could write this same fact as follows:\n{::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot;} ::aes/facts #{[:fox :gives-invitation :invitation1] }}  The above-mentioned fact is just one out of many needed to represent the full story of \u0026ldquo;The Fox and the Stork\u0026rdquo;. In most cases a multitude of facts is required to represent the required knowledge. A set of facts, each consisting of subjects, predicates and objects, form a knowledge graph which provides us with a very general, but precise, way to represent knowledge.\nHowever there are scenarios when we want to represent knowledge about the facts themselves. One way Linked Data/RDF facilitates this is the use of the \u0026ldquo;named graphs\u0026rdquo;. Named graphs allows us to associate an identifier (a URI) with a fact, or a set of facts. This essentially gives a name to a graph in the knowledge base, hence the notion of \u0026ldquo;named graphs\u0026rdquo;. Such an identifier can then be used as a way to add information about the facts with which it is associated.\nThe NQUADS syntax for RDF illustrates one way such named graphs can be represented. In this representation all the elements of the fact: the subject, predicate, object and optionally a graph-name, are written out fully, separated by spaces and concluding with a dot (.) .\nTo take a single fact as an example, here follows a NQUADS format representation that details that \u0026ldquo;for the first invitation the Stork has been invited\u0026rdquo;, and this fact is part of the \u0026ldquo;first dinner\u0026rdquo; named graph:\n\u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; .  For this fact there are four elements to be represented, hence we can refer to these elements together as a quad, versus the notion of a triple for facts just consisting of a subject, predicate and object. As mentioned previously, URIs are used to precisely identify each element: \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; is the subject, \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; is the predicate and \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; is the object respectively. In addition the graph is identified by the URI \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt;.\nThe big benefit of using such identifiers as names for the graphs is that they themselves can be part of facts. For example if we want to express that the facts contained inside the \u0026ldquo;first dinner\u0026rdquo; graph occur before the facts of the \u0026ldquo;second dinner\u0026rdquo; graph, we can use the fact:\n\u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; \u0026lt;http://www.w3.org/2006/time#before\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; .  Note that this fact itself is not part of any named graph. In a knowledge base of facts this would make it a part of the \u0026ldquo;default graph\u0026rdquo;. A default graph is a graph without any particular name. This makes the mixing of \u0026ldquo;regular\u0026rdquo; facts, where each fact consists of a triple, and facts in explicit named graphs, where each fact is a quad, possible in a single knowledge base.\nAn example of a sightly expanded version using of \u0026ldquo;The Fox and the Stork\u0026rdquo;\u0026rdquo; story using named graphs in the NQUADS format can be therefor be as follows:\n\u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; \u0026lt;http://www.w3.org/2006/time#before\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/animal\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/crumbled-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation2\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/narrow-mouthed-jug\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner2\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/fox\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/gives-invitation\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-food\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/soup\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/serves-using\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/shallow-plate\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; . \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/invitation1\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/has-invited\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/stork\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/dinner1\u0026gt; .  Now that we introduced the concept of \u0026ldquo;named graphs\u0026rdquo; we now want introduce a way to represent them in the Clojure representation of Linked Data. Similarly on how in NQUADS the triples are extended to quads to indicate the name of the graph, we extend our previously introduced Clojure syntax to be able to use quads for facts, as opposed to just triples. Similarly to NQUADS the, optional, fourth element of each fact represents the named graph identifier. Any regular triple based fact is part of the default graph in the knowledge base, similarly to the NQUAD representation.\nThe resulting Clojure representation of above-mentioned Linked Data story can be written as follows:\n(def fox-and-stork-named-graph-edn {::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot; :time \u0026quot;http://www.w3.org/2006/time#\u0026quot;} ::aes/facts #{[:fox :rdf/type :animal] [:stork :rdf/type :animal] [:fox :gives-invitation :invitation1 :dinner1] [:invitation1 :has-invited :stork :dinner1] [:invitation1 :has-food :soup :dinner1] [:invitation1 :serves-using :shallow-plate :dinner1] [:stork :gives-invitation :invitation2 :dinner2] [:invitation2 :has-invited :fox :dinner2] [:invitation2 :has-food :crumbled-food :dinner2] [:invitation2 :serves-using :narrow-mouthed-jug :dinner2] [:invitation1 :serves-using :narrow-mouthed-jug :dinner2] [:dinner1 :time/before :dinner2]}})  The main difference between the Clojure representation and NQUADS is that the Clojure representation uses prefixes and NQUADS uses full URIs written out each time. This is a deliberate design choice in syntax from both perspectives. In NQUADS this allows the format to represent each fact on a single line, without the need for a lookup based on context for the full URI of elements. In the Clojure representation the prefixes allow for a much more compact fact representation that makes for easier reading and writing by human users.\nThere are a number of other formats for writing Linked Data, some of which support named graphs. TriG for example is an extension of the Turtle format used in previous articles in this series. JSON-LD is also a very commonly used format for Linked Data that also supports named graphs. With the introduction of the Clojure way of writing Linked Data in this series, it makes sense to enable translating Linked Data into these formats for compatibility and reaching a wider audience. The facts on how to achieve this will be detailed in another article.\n","date":1543878000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543878000,"objectID":"cfa8b7e6bf7f7f73dff49d8c0c6b8754","permalink":"https://www.newresalhaider.com/post/aesopica-3/","publishdate":"2018-12-04T00:00:00+01:00","relpermalink":"/post/aesopica-3/","section":"post","summary":"A way to represent Linked Data using Clojure, with an example based on Aesop's stories. Part 3: Named Graphs.\n","tags":["Clojure","Linked Data","RDF","Semantic Web","knowledge representation","knowledge graph","Aesopica"],"title":"Aesopica, Part 3: Named Graphs","type":"post"},{"authors":null,"categories":null,"content":"This article is the second part of a series, examining the use of the Clojure language for representing Linked Data, with examples from Aesop\u0026rsquo;s stories. Part one can be found on this site where the basic elements of the Fox and the Stork story were formalised. In this article we examine how literal values can be represented, using Clojure, in Linked Data. The code to enable the functionality described in these articles can be found in the Aesopica library for using Clojure to write Linked Data.\nAs mentioned in the previous article the story of the Fox and the Stork is about the fox who invited the stork for a dinner. At the dinner soup was served from a shallow plate that the fox could eat but the stork could not. In return, the stork invited the fox to a dinner, where the food was served in a narrow mouthed jug. This time the fox could not reach the food, while the stork ate it happily.\nElements of this story can be represented as Linked Data, and in particular the Resource Description Framework (RDF) that allows for a precise retelling of the story that is understandable to both humans and machines alike.\nFor example, the part of the Linked Data we generated in the previous article is as follows:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . \u0026lt;fox\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;stork\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;gives-invitation\u0026gt; \u0026lt;invitation1\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;has-invited\u0026gt; \u0026lt;stork\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;has-food\u0026gt; \u0026lt;soup\u0026gt;.  which details the elements of the story that the fox invites the stork, where soup is served. Elements that might be implicitly obvious to a human reader, but not to a program, that the fox and the stork are animals, are also represented in this fragment. These elements are describes as a set of facts, where each fact is a triple in the form of a subject, predicate and object. Each part of these facts in this example are represented as a Uniform Resource Identifier (URI), which are shortened with prefixes (i.e. \u0026quot;rdf\u0026quot;) or the base URI (i.e. \u0026lt;fox\u0026gt; is a shorthand for http://www.newresalhaider.com/ontologies/aesop/foxstork/fox ).\nNow suppose we want to expand on the elements of this story. For example, we want to give the fox and the stork a name, an age, describe their personalities, give a time for the dinners, etc. For many of these elements we want to simply use value as objects in the representations. For example the number 2 as a representative of the age of the fox. In such scenarios we do not use URIs in the facts but Literals.\nLiterals can be used to denote numbers, strings, dates and other such elements. In the Linked Data representation below we describe various attributes of the fox, the stork and the dinner with such literals.\n@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . @prefix foaf: \u0026lt;http://xmlns.com/foaf/0.1/\u0026gt; . @prefix xsd: \u0026lt;http://www.w3.org/2001/XMLSchema#\u0026gt;. \u0026lt;fox\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;fox\u0026gt; foaf:name \u0026quot;vo\u0026quot;. \u0026lt;fox\u0026gt; foaf:age 2. \u0026lt;fox\u0026gt; \u0026lt;is-cunning\u0026gt; true. \u0026lt;stork\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;stork\u0026gt; foaf:name \u0026quot;ooi\u0026quot;. \u0026lt;stork\u0026gt; foaf:age 13. \u0026lt;stork\u0026gt; \u0026lt;is-cunning\u0026gt; true. \u0026lt;dinner1\u0026gt; \u0026lt;has-date\u0026gt; \u0026quot;2006-06-30T20:00:00\u0026quot;^^xsd:dateTime  As one can see in this example, representing literals is very similar to other objects. For example \u0026quot;vo\u0026quot; in the triple \u0026lt;fox\u0026gt; foaf:name \u0026quot;vo\u0026quot; represents the name of the fox. Note that the base of foaf in foaf:name and foaf:age refers to the \u0026lsquo;Friend of a Friend\u0026rsquo; ontology, that allows us to use the common terminology of this ontology to describe facts about the fox and the stork. Literals such as 2 or true describe the age, and whether the fox is cunning, respectively. These are called the lexical forms of the literals and while they also have explicit types (e.g. http://www.w3.org/2001/XMLSchema#string or simply xsd:string when using prefixes ), these types of literals are so common that writing the types explicitly is not required.\nThe slightly more complicated case is the definition of the time of the dinner shown by \u0026quot;2006-06-30T20:00:00\u0026quot;^^xsd:dateTime that shows off custom types for literals, or when we would like to give the type explicitly. Here the addition of the ^^xsd:dateTime is an URI (with a prefix) describing how lexical form, i.e. \u0026ldquo;2006-06-30T20:00:00\u0026rdquo; exactly maps to a particular value. This allows for easier interpretation of such literal values for machines.\nAs in the previous article, we aim to use the data representation and manipulation capabilities of Clojure to represent the above-mentioned fragment. Again, for the basic cases, such as strings, numbers, etc, we can be pretty straightforward and only use the lexical form, i.e. \u0026quot;vo\u0026quot;, 2 or true in or representations. For the cases where we also want to specify a custom datatype, we use a map such as:\n{::aes/value \u0026quot;2006-06-30T20:00:00\u0026quot; ::aes/type :xsd/dateTime}  where the keys ::aes/value and ::aes/type are representing the lexical form and datatype respectively. Note that aes in these keywords, and other refers, to the core namespace of the Aesopica library implementing this data representation. To full Clojure version of this example can be found below:\n{::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot; :foaf \u0026quot;http://xmlns.com/foaf/0.1/\u0026quot; :xsd \u0026quot;http://www.w3.org/2001/XMLSchema#\u0026quot;} ::aes/facts #{[:fox :rdf/type :animal] [:fox :foaf/name \u0026quot;vo\u0026quot;] [:fox :foaf/age 2] [:fox :is-cunning true] [:fox :has-weight 6.8] [:stork :rdf/type :animal] [:stork :foaf/name \u0026quot;ooi\u0026quot;] [:stork :foaf/age 13] [:stork :is-cunning true] [:dinner1 :has-date {::aes/value \u0026quot;2006-06-30T20:00:00\u0026quot; ::aes/type :xsd/dateTime}]}}  Of course given that this story is centuries old, it is unlikely that the dinner took place at 2006-06-30T20:00:00. As always care must be taken when taking things literally.\n","date":1536876000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536876000,"objectID":"34644f83e888a71c681a40a3331419eb","permalink":"https://www.newresalhaider.com/post/aesopica-2/","publishdate":"2018-09-14T00:00:00+02:00","relpermalink":"/post/aesopica-2/","section":"post","summary":"A way to represent Linked Data using Clojure, with an example based on Aesop's stories, Part 2: Literal Values.\n","tags":["Clojure","Linked Data","RDF","Semantic Web","knowledge representation","knowledge graph","Aesopica"],"title":"Aesopica, Part 2: Literal Values","type":"post"},{"authors":null,"categories":null,"content":" The stories called Aesop\u0026rsquo;s Fables or the Aesopica, are an ancient collection of stories that have been passed down to modern day. These stories are of diverse origins they cover a wide variety of themes. Although originally intended for an adult audience, in later times were often used for the education of children.\nOne of such stories is the tale of the Fox and the Stork. There are many versions of this fable, but the overall outline is generally as follows:\n \u0026ldquo;The fox invited the stork to dinner. At the dinner soup was served from a shallow plate, that the fox could eat but the hungry stork could not even taste. In turn the stork invited the fox to a dinner. Dinner was served in a narrow mouthed jug filled with crumbled food. This time the fox could not reach the food, while the stork ate.\u0026rdquo;\n  A 1884 fountain design depicting the story of the Fox and the Stork by Catalan sculptor Eduard Batiste Alentorn in Barcelona  By Jordiferrer - Own work, CC BY-SA 3.0    The intention of stories such as these, as well as text in general, is to convey meaning. However, in addition to humans, a new audience for text has come to light in recent years: machines. To facilitate this new audience a set of technologies has been developed to convey the meaning of text in a precise and unambiguous way that is easily understandable for both humans and machines alike. Many of these new methods fall under the umbrella of the Semantic Web. The goal of the Semantic Web is to create a web of data where the meaning of the information is both human and machine understandable.\nOne of the cornerstone technologies in conveying information for this purpose is Linked Data, and in particular the Resource Description Framework (RDF) standard that defines how this Linked Data can be expressed. I have written a short introduction to Linked Data before but to summarize: it allows for the expressing information as a set of facts. These facts have the form of subject, predicate, object triples. A set of these facts is often called a knowledge base, or in an alternative view this can also been seen as a knowledge graph where the facts define the nodes and edges.\nIn a Linked Data representation the story of Fox and the Stork would look something like this:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . \u0026lt;fox\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;stork\u0026gt; rdf:type \u0026lt;animal\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;gives-invitation\u0026gt; \u0026lt;invitation1\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;has-invited\u0026gt; \u0026lt;stork\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;has-food\u0026gt; \u0026lt;soup\u0026gt;. \u0026lt;invitation1\u0026gt; \u0026lt;serves-using\u0026gt; \u0026lt;shallow-plate\u0026gt;. \u0026lt;stork\u0026gt; \u0026lt;gives-invitation\u0026gt; \u0026lt;invitation2\u0026gt;. \u0026lt;invitation2\u0026gt; \u0026lt;has-invited\u0026gt; \u0026lt;fox\u0026gt;. \u0026lt;invitation2\u0026gt; \u0026lt;has-food\u0026gt; \u0026lt;crumbled-food\u0026gt;. \u0026lt;invitation2\u0026gt; \u0026lt;serves-using\u0026gt; \u0026lt;narrow-mouthed-jug\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;can-eat-food-served-using\u0026gt; \u0026lt;shallow-plate\u0026gt;. \u0026lt;fox\u0026gt; \u0026lt;can-not-eat-food-served-using\u0026gt; \u0026lt;narrow-mouthed-jug\u0026gt;. \u0026lt;stork\u0026gt; \u0026lt;can-eat-food-served-using\u0026gt; \u0026lt;narrow-mouthed-jug\u0026gt;. \u0026lt;stork\u0026gt; \u0026lt;can-not-eat-food-served-using\u0026gt; \u0026lt;shallow-plate\u0026gt;.  This is in the Turtle syntax of RDF. There are other types of syntax are available to represent Linked Data, for example in JSON form as JSON-LD.\nTo summarize a bit of what this Linked Data format does in this scenario, is that it uses Uniform Resource Identifiers (URIs) to define the subjects, predicates and objects of each fact. This allows to precisely and unambiguously define and link the meaning between these elements. For example, the fact that the fox is a type of animal could be expressed by the triple with the full URIs: http://www.newresalhaider.com/ontologies/aesop/foxstork/fox http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://www.newresalhaider.com/ontologies/aesop/foxstork/animal . Due to the fact that writing the full URIs can be quite cumbersome, the Turtle syntax uses two kinds of shorthands to help out. In this case one can define a base URI for the current document, http://www.newresalhaider.com/ontologies/aesop/foxstork, as well as prefixes for other namespeaces, such as http://www.w3.org/1999/02/22-rdf-syntax-ns#, with which the writing of each fact that would begin with these URI fragments could be shortened.\nWhen everything put together this format still describes the original story, albeit restructured into separate facts.\nThere exists many tools for handling Linked Data such as the above story. For example APIs, such as Jena, can aid in the creation, storage and querying of data made available in such a fashion. Of course more and better tools and techniques are always welcome. In this article in particular we hope to describe how we can use the Clojure programming language to enable working with Linked Data.\nClojure is a language that offers a lot of benefits. The focus on manipulating pure data, with immutable data-structures and functional programming, provides an excellent way to organize code. The ability to inter-operate with the Java and JavaScript ecosystems, allows for the use of many mature libraries as well as many avenues for deployment.\nTo use the data manipulation capabilities of Clojure to enable the Semantic Web, seems like a natural combination. Some previous works also aimed at exploring this area, notably EDN-LD which gives a convention and a library for working with Linked Data.\nIn this article we will also explore how we can use Clojure to interact with Linked Data. In our case we will focus on the creation Linked Data from a Clojure environment and we might take different conventions compared to previous work, so we start with a fresh implementation.\nIn Clojure, information is directly represented as data, as opposed to it being encapsulated into various other abstractions such as objects. A large subset of elements data in Clojure is also a data format called the Extensible Data Notation (EDN). The built-in elements in this notation are nil, booleans, strings, characters, symbols, keywords, integers, floating-point numbers, lists, vectors, maps and sets. The meaning behind most of these elements is relatively straightforward, so we only give a brief summary of them here and some examples.\nNil An empty or non-existent element is represented by nil.\nBooleans A boolean value can be true or false.\nStrings Strings are written in double quotes, for example: \u0026quot;This sentence is a string.\u0026quot;.\nCharacters Characters representing single characters, and are preceded by a backslash, for example \\c or \\newline.\nSymbols Symbols are representing identifiers, written by a set of characters (with a few additional rules). Examples of identifiers are for example foo, clojure.core, clojure.string/split. As some of these examples show, in Clojure they are used, among other things to refer to modules and functions. Another interesting feature, as the clojure.string/split example shows, is that they can be namespaced which helps to organize symbols and avoid name collisions.\nKeywords Keywords are very similar to symbols but they are identifiers that refer to themselves. They are constructed much like symbols, but with a leading :. Examples of keywords are :fruit or :company.persons/name.\nIntegers and Floats Integers and floats (floating point numbers) are used, as expected, to write numbers 3 or 4.5 for example.\nAll these elements described above can be put in collections.\nLists Lists are a sequence of values enclosed in (), for example (2 \u0026quot;A string.\u0026quot; false).\nVectors Vectors are a sequence of values enclosed in [], for example [true nil :company/name]. which are designed for random access of its elements.\nSets Sets are collections of unique values enclosed in #{}, such as #{:fruit 2}.\nMaps Finally maps are key value pairs, enclosed in curly braces {}, for example {:name \u0026quot;John Smith\u0026quot;, :age 4}, where each key is unique. Of course collections can also nested any type of collection.\nUsing this notation elements of EDN, we can build an EDN based version of the story of the Fox and the Stork, using some conventions.\nGiven that in many practical cases we are probably going to shorten URIs with prefixes when writing, we can use a keyword for denoting elements. In the case where we would use the base prefix, we can just use a regular, non-namespaced, keyword, i.e. :fox, and in cases where we would refer to any other prefix we can use namespaced keywords, i.e. :rdf/type. A full fact could then be described with a relatively straightforward vector, for example [:fox :rdf/type :animal] and the knowledge base with a set of facts such as #{[:fox :rdf/type :animal] [:stork :rdf/type :animal]}.\nOf course this means that in addition to facts we also need some data for the context, in which we store the base and other prefixes and to what they map to, to be able to fully build an equivalent Linked Data representation. The context will be a map of the relevant prefixes as keys, as well as nil for the base prefix. For the above example this means that the below example will describe the context needed to resolve all the full URIs:\n{nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot;}  Putting everything together, to have a full Linked Data graph we need a context and a set of facts, so the overall structure will be a map where these are both defined:\n{::aes/context {nil \u0026quot;http://www.newresalhaider.com/ontologies/aesop/foxstork/\u0026quot; :rdf \u0026quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026quot;} ::aes/facts #{[:fox :rdf/type :animal] [:stork :rdf/type :animal] [:fox :gives-invitation :invitation1] [:invitation1 :has-invited :stork] [:invitation1 :has-food :soup] [:invitation1 :serves-using :shallow-plate] [:stork :gives-invitation :invitation2] [:invitation2 :has-invited :stork] [:invitation2 :has-food :crumbled-food] [:invitation2 :serves-using :narrow-mouthed-jug] [:fox :can-eat-food-served-using :shallow-plate] [:fox :can-not-eat-food-served-suing :narrow-mouthed-jug] [:stork :can-eat-food-served-using :narrow-mouthed-jug] [:stork :can-not-eat-food-served-suing :shallow-plate]}}  I have started a small library for manipulating Linked Data structures written this way, with the name Aesopica. It is in very early stages, where the current main functionality is to translate Linked Data written this way into the Turtle format described above.\nOf course there are lot of other elements of Linked Data that needs to be represented in this that we did not tackle yet. In addition there are also a large number of Clojure libraries that could be used to make writing and using Linked Data in this fashion easier. How these features could be achieved however is a story for another time.\n","date":1536530400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536530400,"objectID":"6c6d4a6e2c8c2db71b1567928a64428a","permalink":"https://www.newresalhaider.com/post/aesopica-1/","publishdate":"2018-09-10T00:00:00+02:00","relpermalink":"/post/aesopica-1/","section":"post","summary":"A way to represent Linked Data using Clojure, with an example based on Aesop's stories, Part 1: General Introduction.\n","tags":["Clojure","Linked Data","RDF","Semantic Web","knowledge representation","knowledge graph","Aesopica"],"title":"Aesopica, Part 1: General Introduction","type":"post"},{"authors":null,"categories":null,"content":"History is full of legends of ancient treasures and powerful artifacts, lost to time or hidden by purpose, that would bring glory, power and riches to their discoverer.\n A winged bull depicted on an on archaeological artifact from the Assyrian empire between 1400 and 1200 BC. Cylinder Seal with Winged Bull - Walters Art Museum Licensed under CC0.   Although the history of software development is much shorter than the history of mankind, there already exists artifacts that have near mythological status when it comes to software development, yet often go hidden underneath the surface. One of these is the language of Common Lisp.\nCommon Lisp is a language originally from the early 80s, and was a standardization of many dialects of the Lisp programming language, which explains both the Common and Lisp part of the name. Lisp itself is one of the oldest general purpose programming languages, first specified in 1958. From Lisp many ideas that we consider common in other languages were popularized, such as conditionals (the if and else structure), notion of functions as first class elements, and many others (see this article on more of these ideas). Common Lisp is also often mentioned as an amazing and fun language to learn, which makes it the clear-cut choice for this article.\nAs the story goes it gives the user untold levels of productivity and joy of development. One other big advantage is that Common Lisp used to be the language of A.I. research. There is lots of existing code out there for systems on the subject of knowledge representation, reasoning and planning. Given the resurgence of fields such as a Semantic Web that make use of such A.I. systems, learning from such tools and techniques, or even using them directly, can be invaluable. In this post, I aim to find out a very small portion of the riches we can dig up using Common Lisp, and to share this experience with the reader.\n Cylinder Seals were common objects that were used to designate ownership in ancient Mesopotamia. Although describing to a different notion of \u0026lsquo;common\u0026rsquo; these show remarkable of craftsmanship that we hope to introduce ourselves to in Common Lisp. Cylinder Seal with Two Heroes and a Tree - Walters Art Museum Licensed under CC0.   To add as a disclamer, I do have experience with a similar language, Clojure that I use in my day-to-day programming, as well as with Emacs (namely Spacemacs), so I probably have some head start in using and editing the language. Nonethess I aim to make this introduction accessible to readers without such knowledge.\nWith any treasure hunt, preparation is often key. As we are unfamiliar with the language itself it is good to read guides and tutorials to prepare. The guide to selecting the right equipment for our adventure is the cl-cookbook, which describes how to get started with Common Lisp.\nCommon Lisp is a language with multiple implementations. As recommended by our guide we are using Steel Bank Common Lisp (SBCL) as distribution and using Roswell to manage it. Alternatively a more straightforward install is Portacle that could be used.\nNext is testing whether our implementation is working. We run the Read–Eval–Print Loop (REPL), which in the case of Roswell can be done with the command ros run. What the REPL allows us to do is interactively develop our code by reading our input, evaluating it and printing the results. This is one of the many features in programming that originated with Lisp, but has since made its way to many other languages.\nNow the question is how we should write Common Lisp. One really nice resource for quickly familiarizing with new languages is Learn X in Y minutes, which also has a nice introduction to Common Lisp. One of the most striking features of a Lisp, is the syntax of it. Elements are either atoms, that evaluate to themselves, such as the number 4 or s-expressions which are a list of expressions in brackets, such as (+ 3 2). Atoms evaluate to themselves, so if we write 4 in the REPL, we get 4 returned back. For s-expressions they are in the form of (function param1 param2 ...), so in the case of (+ 3 2) this will evaluate to 5. One can of course nest these forms, for example (+ 3 (+ 3 2)) will result in 8. In addition to functions there are macros available creating completely different forms to be translated into code. We will see some examples of this later in the article.\nWith the REPL now working it is time to set up a project where we can write down all the code we need for our digging. According to our cookbook tutorial we can do this from the REPL, by getting cl-project, and using it.\n(ql:quickload \u0026quot;cl-project\u0026quot;) (cl-project:make-project #P\u0026quot;./common-treasure\u0026quot;)  This will give us the outline of project in the common-treasure directory. The files generated include a readme, systems for the project itself as well as tests and of course some skeletons for a test and a package itself respectively.\nFirst we are going to start off figuring out the package itself. Like in many other languages, functionality can be grouped together units, in this case packages. The generated file outline looks like this:\n(defpackage common-treasure (:use :cl)) (in-package :common-treasure) ;; blah blah blah.  From the looks of it, it says to us that it defines a package named common-treasure using :cl, which I assume is another package. There is also a call to in-package which looks like is there to ensure that everything else that follows is also in this package. Finally the ;; blah blah blah. portion looks like a comment, something to describe functionality with, but nothing to be executed.\nNow in order to see if everything is working correctly let\u0026rsquo;s load this package. Instead of using the REPL from the command line, we are using it directly from our editor, in this case an Emacs distribution named Spacemacs. Without going into much detail about Emacs it can be described as a highly configurable editor for pretty much any programming language out there. SLIME: The Superior Lisp Interaction Mode for Emacs ensures that our interaction with the REPL and the various language features go much more smoothly by integrating it with our editor of choice.\nEmacs is incredibly configurable, which is where Spacemacs comes in. It provides a set of curated configurations named layers, that make setting up the configuration for a particular language a breeze. We just enable the common-lisp layer of Spacemacs in the configuration file, add a small piece to let Emacs know of our Common Lisp distribution (see link), and we are good to go.\nWith everything setup now we can start our treasure hunt a bit more in earnest by starting SLIME. We are greeted by the message \u0026ldquo;Connected. Hack and be merry!\u0026rdquo; as well as a REPL in a window. Lets start to dig around by figuring out what exactly all the elements do. We can use the command slime-describe-symbol to get some more information about defpackage and what it does. This brings up some documentation on defpackage. It shows us that this is a macro, as well as the various options one can use with it. A macro, without going into too much detail, is essentially a way to convert forms into different ones before evaluating them. We can get a bit more info on the workings by calling the command slime-hyperspec-lookup. This takes us to the Common Lisp Hyperspec with more detailed docs. The pages for defpackage and inpackage more or less confirm their use is as we expected.\nNow it is time to start writing some new code. We remove the comments and create a function named hello-treasure, that should just print the text \u0026ldquo;Hello Treasure\u0026rdquo;. We add the following to our file:\n(defun hello-treasure () (print \u0026quot;Hello Treasure!\u0026quot;) )  in place of the comments, and we run the command slime-complile-and-load-file. Compilation succeeds, but when we aim to call the function (common-treasure:hello-treasure) get an error when trying to call the function, saying \u0026ldquo;The symbol \u0026ldquo;HELLO TREASURE\u0026rdquo; is not external to the \u0026ldquo;COMMON TREASURE\u0026rdquo; package.\u0026ldquo;. This due to the fact that we did not declare the function external in the defpackage package declaration.\nWhat is really interesting is that, although we have this issue, instead of just failing the SLIME REPL presents us with a number of options. For example we can 0: [Continue] Use symbol anyway., 1: [Retry] Retry SLIME REPL evaluation request., 2: [*Abort] Return to SLIME's top level.. In this case we can just abort, and modify the package declaration, but it is interesting to be offered all these options.\nBy adding (:export :hello-treasure) to the defpackage macro, we can do another call and it indeed returns \u0026ldquo;Hello Treasure!\u0026rdquo; in the REPL.\nNow that we got the basics down we would like to have a slightly bigger example in which we make use of an existing library. While digging around for the software languages and libraries of the past is often the matter of some searching, reading, coding and a bit of trial and error. Digging around in the world is process governed by various regulations and laws. This is especially true in cities with long history, where a regular building site can easily unearth archaeological finds.\n Digging in the certain urban areas can easily lead to excavations done before any subsequent work is done. Romano-Celtic temple excavated in London.   In particular, there are often a set of regulations that specify whether one can dig in areas of archaeological interests. As an example we use a portion of the rules by the municipality of Utrecht, as described on a map of Utrecht and surrounding areas (in Dutch).\nThese regulations can be summarized by a number of rules, based on two conditions: the type of area and the size of the area that is to be disturbed.\n If the area is of high archeological value, then a permit is required no matter what the size of the area is to be disturbed.\n If the area is of high archeological expectation, then a permit is required when the size of the area that is to be disturbed is larger than 100m2.\n If the area is of archeological expectation, then a permit is required when the size of the area that is to be disturbed is larger than 1000m2.\n  Such regulations can be encoded into a regular function that returns a true or false to the question \u0026ldquo;Is the a permit required?\u0026rdquo; based on two parameters, the size of the area and the type of the area. However this could be more complicated and harder to maintain if the set of regulations, along with conditions and outcomes, become more complex.\nThere are various approaches to deal with this issue. One of these is to encode the facts on which our answer relies into a knowledge base, and have a general mechanism to derive new knowledge from existing facts. This later process is often denoted as inferring or reasoning to derive new knowledge. Such an approach can make it easier to use and maintain such a system.\nFor this article we are going to implement such an approach using LISA. This is a production rule system, in which the knowledge base is encoded in a set of facts, and rules are uses as a way to derive new knowledge. It is easy to see how such a system would be a good fit for our problem: our domain restrictions are already formulated as a set of rules. It would also allow us to use some existing libraries, to see more of what Common Lisp has to offer.\nTo start off, first we need to add a dependency to LISA into our system. One of the files created by cl-project is an asdf file that describes how to build the software we are creating. Here we can add the dependency on Lisa, resulting in the following file:\n#| This file is a part of common-treasure project. |# (defsystem \u0026quot;common-treasure\u0026quot; :version \u0026quot;0.1.0\u0026quot; :author \u0026quot;\u0026quot; :license \u0026quot;\u0026quot; :depends-on (\u0026quot;lisa\u0026quot;) ;; Here we add the dependency on LISA. :components ((:module \u0026quot;src\u0026quot; :components ((:file \u0026quot;common-treasure\u0026quot;)))) :description \u0026quot;\u0026quot; :long-description #.(read-file-string (subpathname *load-pathname* \u0026quot;README.markdown\u0026quot;)) :in-order-to ((test-op (test-op \u0026quot;common-treasure-test\u0026quot;))))  Now we just need to make sure the dependencies needed are actually downloaded and available. For this we use quicklisp which is the library manager Common Lisp. By using the command (ql:quickload \u0026quot;common-treasure\u0026quot;) we can get all the dependencies for our system, which in this case consists of just LISA.\nNow in order to translate our example scenario, we look at some of the examples that are available for LISA. A typical system consists of a knowledge base, in which facts are defined as Common Lisp Object System (CLOS) objects and rules to manipulate such instances as the reasoning method.\nCLOS is a way in which Common Lisp can do object-oriented programming, and LISA co-opts this as a way to represent facts in the knowledge base. Without going into detail on object-oriented programming theory, this allows one to, define classes, create instances of those classes and define methods that make use of those classes (see this nice intro on Common Lisp Object System (CLOS) for its general use).\nIn the context of LISA, these allow us to represent classes of facts, specific instances of facts, and methods that can be used with those facts. For example we can represent the type of facts in our domain with two classes of objects: one that represents \u0026ldquo;area\u0026rdquo; and one that whether \u0026ldquo;a permit is required\u0026rdquo;. In Common Lisp these can be defined with the defclass macro. So for our example the following would be a call for permission requirement:\n(defclass permit-required () () )  In case of the area, we need to represent two facts about it: what the archaeological type of it is, and what size of the area is disturbed. Such elements of the classes are described in CLOS using slots. There are many possible options that are available to describe a slot:\n :initarg describes the name of the slot. :initform is the default value it is given initially. :accessor can be used to define a function for accessing the slot value.  Putting this together gives us the following class for representing the area:\n(defclass area () ((archeological-type :initarg :archeological-type :initform \u0026quot;\u0026quot; :accessor :archeological-type) (size-disturbed :initarg :size-disturbed :initform 0.0 :accessor :size-disturbed) ))  Now that we figured out how represent facts, we need to encode the rules of our domain into our system. We can do this with 3 rules that describe what to do in the cases of high archeological value, high archeological expectation and archeological expectation\nThe rules themselves described with three parts:\n The antecedent, which is the set of conditions that have to be true. The arrow sign =\u0026gt; . The consequent, which contains the facts that need to be derived or any actions that we want to perform.  In the case of LISA, and in many other rule based definitions, the antecedent and the consequent are also called Left Hand Side (LHS) and Right Hand Side (RHS), as they are respectively on the left and right hand side of the arrow. What exactly can be put into the LHS and RHS is dependent on the language for the rule definitions, but one standard way they are used is in the LHS the conditions are described based on the facts that could be in the knowledge base, and on the RHS facts are added in the knowledge based on the meaning of the rule. For example for one of our rules, if the know the fact that our area is of high archaeological value (LHS), we can derive the fact that we need a permit (RHS).\nDescribing our three rules this way in LISA looks as follows, using the defrule macro:\n;; If the area is of high archeological value, then a permit is required no matter what the size of the area is to be disturbed. (defrule high-value () (area (archeological-type \u0026quot;high-value\u0026quot;)) =\u0026gt; (assert ((make-instance 'permit-required)))) ;; If the area is of high archeological expectation, that a permit is required when the size of the area that is to be disturbed is larger than 100m\u0026lt;sup\u0026gt;2\u0026lt;/sup\u0026gt;. (defrule high-expectation () (area (archeological-type \u0026quot;high-expectation\u0026quot;) (\u0026gt; size-disturbed 100)) =\u0026gt; (assert ((make-instance 'permit-required)))) ;; If the area if of archeological expectation, that a permit is required when the size of the area that is to be disturbed is larger than 1000m\u0026lt;sup\u0026gt;2\u0026lt;/sup\u0026gt;. (defrule expectation () (area (archeological-type \u0026quot;expectation\u0026quot;) (\u0026gt; size-disturbed 1000)) =\u0026gt; (assert ((make-instance 'permit-required))))  The rules are reasonably straightforward, in that they require the condition matching in the knowledge base, before they assert an instance of the permit-required fact into the knowledge base.\nThese together already describe the domain, but for this article we also show how things work with two examples. In one scenario we assert that we have an area with high-value archaeological type and a to be disturbed are with the size of 2000m2. In this case we would need a permit, due to our high-value rule. In the second scenario, the area is of high-expectation but the size of the area disturbed is only 10m2. In this case none our rules will fire, and no permit-required fact instance is put into the knowledge base.\nExecuting the system is just a matter of adding these facts in the knowledge base and letting the system run. In LISA adding a fact can be done using assert similarly to what the RHS of the rules are doing. To actually run the system, unsurprisingly, the function run can be called. To see what facts are in the knowledge base the function facts prints them out for us to see. To tie things together, we make sure that the knowledge base is reset before we execute anything using reset.\nBelow is the full example implementation that we put together:\n(defpackage common-treasure ) (in-package :lisa-user) (reset) (defclass area () ((archeological-type :initarg :archeological-type :initform \u0026quot;\u0026quot; :accessor :archeological-type) (size-disturbed :initarg :size-disturbed :initform 0.0 :accessor :size-disturbed) )) (defclass permit-required () () ) ;; If the area is of high archeological value, then a permit is required no matter what the size of the area is to be disturbed. (defrule high-value () (area (archeological-type \u0026quot;high-value\u0026quot;)) =\u0026gt; (assert ((make-instance 'permit-required)))) ;; If the area is of high archeological expectation, that a permit is required when the size of the area that is to be disturbed is larger than 100m\u0026lt;sup\u0026gt;2\u0026lt;/sup\u0026gt;. (defrule high-expectation () (area (archeological-type \u0026quot;high-expectation\u0026quot;) (\u0026gt; size-disturbed 100)) =\u0026gt; (assert ((make-instance 'permit-required)))) ;; If the area if of archeological expectation, that a permit is required when the size of the area that is to be disturbed is larger than 1000m\u0026lt;sup\u0026gt;2\u0026lt;/sup\u0026gt;. (defrule expectation () (area (archeological-type \u0026quot;expectation\u0026quot;) (\u0026gt; size-disturbed 1000)) =\u0026gt; (assert ((make-instance 'permit-required)))) ;;Test fact 1 ;; (assert ((make-instance 'area :archeological-type \u0026quot;high-value\u0026quot; :size-disturbed 2000))) ;;Test fact 2 (assert ((make-instance 'area :archeological-type \u0026quot;high-expectation\u0026quot; :size-disturbed 10))) (facts) (run) (facts)  Note that here the fact 1 is commented out, to test the assert of fact 2, so that running the other scenario is just a matter of commenting and un-commenting the relevant lines.\nFor the first scenario, with fact 1, the output of our initial program is as follows:\n[package common-treasure]#\u0026lt;INITIAL-FACT ; id 0 {1002669853}\u0026gt; #\u0026lt;AREA ; id 1 {1002745373}\u0026gt; For a total of 2 facts. #\u0026lt;INITIAL-FACT ; id 0 {1002669853}\u0026gt; #\u0026lt;AREA ; id 1 {1002745373}\u0026gt; #\u0026lt;PERMIT-REQUIRED ; id 2 {100283A363}\u0026gt; For a total of 3 facts.  Note that we print out our facts twice, once before the run and once after, but it shows that now the permit requirement was derived.\nFor the case of using fact 2 , we get the following output:\n[package common-treasure].#\u0026lt;INITIAL-FACT ; id 0 {1004D40AB3}\u0026gt; #\u0026lt;AREA ; id 1 {10020107C3}\u0026gt; For a total of 2 facts. #\u0026lt;INITIAL-FACT ; id 0 {1004D40AB3}\u0026gt; #\u0026lt;AREA ; id 1 {10020107C3}\u0026gt; For a total of 2 facts.  This shows that our fact base did not change due to our running the reasoning system.\nSo there we have it, a bit of a peek of what can be done with Common Lisp. I have to say the language and its various features are quite a bit daunting, as I feel I have only scratched the surface of what is possible, with both interacting with the language as well as with A.I. tools such as LISA. That said digging into the language and seeing how it can handle a small, but also relevant scenario, felt like a worthwhile journey, and that is an experience always worth treasuring.\n","date":1530309600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530309600,"objectID":"07a75a7895c06ac3d8c67d402f4b9c79","permalink":"https://www.newresalhaider.com/post/common-treasure/","publishdate":"2018-06-30T00:00:00+02:00","relpermalink":"/post/common-treasure/","section":"post","summary":"Discovering the benefits of Common Lisp by figuring out what can one dig up.\n","tags":["Common Lisp","reasoning","rules","rules engine","knowledge representation","archeology","law"],"title":"Excavating a Common Treasure","type":"post"},{"authors":null,"categories":null,"content":"Spider-Man is one of the most iconic heroes of the Marvel universe. Created by Stan Lee and Steve Ditko, Spider-Man is a regular teenager named Peter Parker, who due to being bitten by a radio-active spider, gains abilities such as the proportional strength of a spider, wall crawling and a spider sense to detect upcoming danger. One of the biggest draws of Spider-Man that although he is a superhero and fought various villains from cosmic beings to petty criminals, he also had to deal with regular everyday problems, such as money issues, school life and the pressure of a job.\n The Spectacular Spider-Man © Marvel Entertainment   In software there are also everyday problems which one has to tackle before one can defeat the villains of the domain at hand. One of these everyday problems is the issue of data validation. Data validation is the process of ensuring that the elements of the data are correct. This process has to be done in pretty much all domains when working with actual data. Consider the financial domain where a financial product can only be made available if the right requirements are fulfilled in the request. If the request is not written correctly then the request needs to be denied. In the legal and regulatory domains certain information that is required for a law must be fulfilled, otherwise costly corrections or fines can follow. Another good example is the clinical domain, where the a patients data needs to be transferred to an application. Here is it essential that this data fulfills the requirement for requesting a clinical procedure or a medication, as any mistake can lead to huge negative impact on the health of the patient.\nOne relatively recent tool that can be used to solve this problem is the clojure.spec library in the Clojure programming language. In this article we aim to explain, alongside Spider-Man, how these specs can be used to tackle the data validation problem in a spectacular way. As this library relies on the Clojure language some knowledge of Clojure is needed. In order to make this article understandable to those without such prior expertise we introduce some aspects of Clojure. In particular we focus on two features of it: the way information (data) is represented and the fact that it is a Lisp.\nIn Clojure data is represented with relatively few elements that are combined together. Take for example a scenario where we want to create a profile of Spider-Man, as taken from the Marvel wiki entry on Spider-Man.\nThe full name of Spider-Man can be represented in text form as a string. Like in many other languages the text is placed in between quotation marks.\n\u0026quot;Peter Benjamin Parker\u0026quot;  For the numbers to represent his relative power in the Marvel universe, we use natural numbers (we leave the concepts and issues surrounding very large or floating point numbers out in this article). In case of Spider-Man his durability is 5:\n5  Of course having just a value of the name and the durability of Spider-Man just floating around makes the representation somewhat incomplete, as they are not attached to the concepts of \u0026ldquo;name\u0026rdquo; or \u0026ldquo;durability\u0026rdquo;. Just like how Spider-Man needs buildings to sling off of, we need a representation that links the values with what they represent. In Clojure, keywords are often used for this purpose.\n:real-name  :spider-man-spec.core/name  ::durability  Keywords are symbolic identifiers. Think of them as symbols, much like one would use a string, but with some special powers attached. They are text prefaced by \u0026ldquo;:\u0026ldquo;, as it can be seen in the keyword :real-name. They have the ability to be namespace-qualified, such as :spider-man-spec.core/name which indicates that this is the keyword in the spider-man-spec.core namespace. Namespaces are what allows us to modularize our data and code, by grouping them under together a single identifier. In our case this is spider-man-spec.core. This namespacing ensures that our definition of the concepts of \u0026ldquo;name\u0026rdquo;, \u0026ldquo;real-name\u0026rdquo;, \u0026ldquo;durability\u0026rdquo;, etc. can remain distinct from any other use of similar concepts. Finally, when writing internally to the library which uses the namespace, or when aliasing to it, we can just shorten the keyword with \u0026ldquo;::\u0026ldquo;, such as in ::durability.\nKeywords come with some nice implementation details, such as fast equality checks and some other powers we will show in the future. This makes them the preferred keys in data-structures such as maps. And speaking of maps they allow the description of information in key-value pairs, as written between curly braces in the small example below.\n{::name \u0026quot;Spider-Man\u0026quot; ::real-name \u0026quot;Peter Benjamin Parker\u0026quot;}  The curly backets around the pairs express the keys and values in a map in Clojure. In the above example ::name and ::real-name are the key and value pairs for \u0026quot;Spider-Man\u0026quot; and \u0026quot;Peter Benjamin Parker\u0026quot; respectively.\nMaps are just one of the ways one can describe a collection of elements. You also have sets, collections in which each element is unique. This can be done with a hashtag and some curly brackets \u0026ldquo;#{}\u0026rdquo;. In the example below we list the current and former affiliations of Spider-Man.\n{::current-affiliations #{\u0026quot;Avengers\u0026quot;} ::former-affiliations #{\u0026quot;Secret Defenders\u0026quot; \u0026quot;New Fantastic Four\u0026quot; \u0026quot;The Outlaws\u0026quot;}}  Note that how sets are used within maps to represent this knowledge. This is actually a common way to represent knowledge in Clojure: you combine all the various data representations directly. This way you can have a list containing maps, with keywords as keys and values that contain maps and strings, where the maps contain numbers, etc. You have these data-structures in pretty much all commonly used programming languages. Where Clojure differs from many is that it does not put (almost any) sugaring or abstraction on top.\n Spider-Man swinging around the city. © Marvel Studios   Just as Spider-Man is often at his best when he is just being \u0026ldquo;plain old Spidey\u0026rdquo;, having data represented this way has some nice advantages. The biggest is simplicity. Instead of learning to work with specific wrappers, objects, prototypes, etc on top of this data, that can differ between applications and libraries, it is enough to learn how to handle and manipulate maps, list, sets once. This knowledge can be then reused in any domain, and frees up the attention of the programmer to focus on the domain problem, and not the exact way the data was wrapped up in a library.\nThis of course also means that a system, such as clojure.spec, that aims at data validation in Clojure, has to handle the above-mentioned style of composition well. But before we get ahead of ourselves lets finish up by providing the profile of Spider Man.\n(def spider-man-profile {::name \u0026quot;Spider-Man\u0026quot; ::real-name \u0026quot;Peter Benjamin Parker\u0026quot; ::identity ::secret ::affiliations {::current-affiliations #{\u0026quot;Avengers\u0026quot;} ::former-affiliations #{\u0026quot;Secret Defenders\u0026quot; \u0026quot;New Fantastic Four\u0026quot; \u0026quot;The Outlaws\u0026quot;}} ::power-grid { ::durability 3 ::energy 4 ::fighting 5 ::intelligence 4 ::speed 5 ::strength 4 } } ) (def vulture-profile {::name \u0026quot;Vulture\u0026quot; ::real-name \u0026quot;Adrian Toomes\u0026quot; ::identity ::publicly-known ::affiliations {::current-affiliations {} ::former-affiliations #{\u0026quot;Sinister Twelve\u0026quot; \u0026quot;Sinister Six\u0026quot;}} ::power-grid { ::durability 4 ::energy 3 ::fighting 4 ::intelligence 4 ::speed 5 ::strength 3 } } ) (def spider-man-characters [spider-man-profile vulture-profile])  Oh no, our Spider Senses should be tingling. It is Vulture, that has shown up in our list of Spider-Man characters. In addition we just introduced some new elements in our example that need some explanation for readers new to Clojure.\n Uh oh, Vulture must be up to no good if he shows up here. © Marvel Studios   The first is the use of square brackets [], which indicate a list. This is a collection of elements, in this case of spider-man-profile and vulture-profile, that unlike a set, can have multiples of the same element.\nThe other new type of element we use is the form of using parentheses along side def as in (def spider-man-characters ...). Expressions of these type, called symbolic expressions, or s-expressions for short, are a characteristic of the Lisp family of languages to which Clojure belongs to. In a Lisp, parts of the program are either atoms, such as 5, \u0026quot;Peter Benjamin Parker\u0026quot;, true, or an s-expression where the first element between parens is a function and the rest are parameters. For example (+ 1 3). While atoms evaluate to themselves, the s-expressions evaluate to a function with the given parameters. In the case of (+ 1 3) they should evaluate to 4. You can also nest s-expressions, such as (- (+ 1 3) 2), which will evaluate to 2.\nYou might be thinking, \u0026ldquo;Wait, if everything is either an atom or an s-expression, what kind of villainous things are those strange brackets that one has to use to create a set, list or map!\u0026rdquo;. For all the simplicity in Clojure, it does make use of some syntactical sugar. Lists can be written [spider-man-profile vulture-profile] as a shorthand for the s-expression (list spider-man-profile vulture-profile). Similar functions exist for maps and sets as well.\nMuch like Spider-Man, who for all his powers still has to struggle with juggling a school and a job and has to make practical decisions, Clojure has to make them as well. In this case because certain things, such as maps, sets and list are used so often, it uses a shorter syntax for creating them. This does makes the language slightly more complex, but in the author\u0026rsquo;s view, it pays off.\nAnother matter of practicality of course is that while we can nest the two profiles directly into a list, we can create variables for them to associate. The def function does exactly this, and it also ensures they become part of the current namespace. For example, if the current namespace is spider-man-spec.core then a def of vulture-profile can be referred to as spider-man-spec.core/vulture-profile from other namespaces, and simply vulture-profile in the current namespace. This allows us to break up the overall data in smaller parts to use.\nNow we finally described the profiles of both Spider-Man and Vulture, but are they correct? The library of clojure.spec uses the notion of a spec for this. A spec is simply a function on a single parameter that returns a truthy value (in most cases a true if the spec holds, false if the spec does not hold).\nIn essence this allows for many existing functions to be used as specs. For example the already existing function string? checks whether a particular value is a string or not.\nIn order to check whether a value is valid for a particular spec we can use the s/valid? function. Here the s stands the namespace of the spec library clojure.spec.alpha, so by calling s/valid? we are calling the valid? function of this particular namespace.\n(s/valid? string? \u0026quot;Spider-Man\u0026quot;)  The above function call will checking if \u0026quot;Spider-Man\u0026quot; is indeed a string, and return true if it is. On the other hand if we check whether a number is valid for this spec, using (s/valid? string? 6) we instead get false returned.\nAnother way to use a spec, is to explain why a value is wrong. For example, we can call the function explain-data on with the spec and an incorrect value, to get a map back with an explanation. The function call:\n(s/explain-data string? 6)  would result in the map:\n{:val 6 :predicate :clojure.spec.alpha/unknown}  Now the above example clearly shows the value on which the spec has failed, but it denotes the predicate as unknown with :clojure.spec.alpha/unknown. The solution to this is to provide a name for the spec, which the system can use to pin point if things fail. We can register any spec using the function s/def. For example the functions:\n(s/def ::name string?) (s/def ::real-name string?)  will register the two specs under the keys :name and :real-name in the current namespace, i.e.: under spider-man-spec.core/name and spider-man-spec.core/name respectively.\nNow if we would aim to explain why the spec :real-name does not allow the value 6, it would return the explanation:\n{:val 6 :predicate :spider-man-spec.core/real-name}  where the predicate now identifies the spec that was not fulfilled.\nSpecs can also be created in other ways. For example a set of values indicating the correct values can be used as a spec.\n(s/def ::identity #{::secret ::publicly-known})  The above code defines a spec for identity as having two possible values: either ::secret or ::publicly-known.\nSpecs can also be defined for collections as well. The specs for current- and former affiliations:\n(s/def ::current-affilications (s/coll-of string? :kind set?)) (s/def ::former-affilications (s/coll-of string? :kind set?))  These specs describe that that both current- and former have to be sets of strings. The affiliations part of a profile is actually map containing both current- and former affiliations. This is defined as the spec:\n(s/def ::affiliations (s/keys :req [::current-affiliations] :opt [::former-affiliations]) )  which makes it requirement for affiliations to contain current-affiliations, but any former affiliations are optional.\nFor checking whether Spider-Man has a valid profile we can use the s/valid? function again. We use the following code to do just that:\n(let [spider-man-affiliations (:spider-man-spec.core/affiliations spider-man-profile)] (s/valid? :spider-man-spec.core/affiliations spider-man-affiliations))  The let form is new here, but what it essentially does is deconstructing the while spider-man-profile and associating its affiliations temporarily the spider-man-affiliations. This allows us to use a shorthand when calling functions, instead of writing out everything in a single line.\nWhile this value is also valid according to the spec, as the spec and the value we are checking gets more complex, it could also be useful to gather the exact value that has passed the spec. In such cases we can use s/conform to gather these. The call:\n(s/conform :spider-man-spec.core/affiliations spider-man-affiliations)  Returns the map:\n#:spider-man-spec.core{:current-affiliations #{\u0026quot;Avengers\u0026quot;}, :former-affiliations #{\u0026quot;The Outlaws\u0026quot; \u0026quot;Secret Defenders\u0026quot; \u0026quot;New Fantastic Four\u0026quot;}}  Note that this is a namespaced map, which is a feature that allows us to refer to the keywords inside a map more efficiently, instead of writing them all out in each case.\nThe final aspect of each profile, the power grid, is also something that can be given a spec. Each of the powers can only take a whole number value from 1 until 7. We can specify this with the follow spec:\n(s/def ::power-value (s/and pos-int? #(\u0026gt;= % 1) #(\u0026lt;= % 7))) (s/def ::durability ::power-value ) (s/def ::energy ::power-value ) (s/def ::fighting ::power-value ) (s/def ::intelligence ::power-value ) (s/def ::speed ::power-value ) (s/def ::strength ::power-value )  Note that we use the function s/and to combine three specs: that the value should be a positive integer, greater than or equal to 1 and less or equal to 7. Such a combined spec can then be (re-)used like any other.\nWe can combine all the previous specs together to specify a profile:\n(s/def ::profile (s/keys :req [::name ::real-name ::identity ::affiliations ::power-grid] ) )  For this spec, both Spider-Man and Vulture are valid profiles. However, this is a problem, as it does not allow us to differentiate between a hero and a villain. Of course we do not want to get Vulture get into the same places as Spider-Man can. We must fight him, much like Spider-Man, but in our own way: by creating a spec for which the Spider-Man profile is a valid value, but not that of Vulture.\n Spider-Man vs Vulture © Marvel Entertainment   While we can make a separate requirement that only persons with the name \u0026ldquo;Spider-Man\u0026rdquo; can fulfill our new \u0026ldquo;hero-spec\u0026rdquo; this might be too restrictive. Instead we are going to spec an Avenger profile, so Spider-Man and all his friends can join in, while villains such as Vulture are kept out.\nThe requirement for an Avenger in our system, is that any-one with the current affiliation of \u0026quot;Avengers\u0026quot; is an avenger. We can describe this requirement as a spec, using a function defined for this:\n(defn is-avenger? [profile] (contains? (::current-affiliations (::affiliations profile) ) \u0026quot;Avengers\u0026quot;) ) (s/def ::avenger-profile (s/and ::profile is-avenger? ) )  Now we can check whether a profile is a valid Avenger, which will be true for Spider-Man but not for Vulture. Finally, we can get rid of this villain that showed up in our tutorial. In addition, this spec will also make sure that all current members of the Avengers be valid, so Spider-Man can fight freely alongside of them.\n Our spec answers the question posed in this cover: Spider-Man is indeed an Avenger © Marvel Entertainment   So there we have it, a brief look at using the spec library to validate data. There are many things that I have not touched, such as the ability to generate values based on the Spec, other ways to compose a spec, etc.\nNonetheless I hope this article gives a solid introduction, and maybe an interest to using the spec library, even if one does not have a Clojure or even a heavy programming background. The source code snippets are available at: Spider-Man-Spec.\nIf you have a data validation problem, by all means take a swing at it with the Spec library. I am convinced that the results you will get will be nothing short of spectacular.\n","date":1524952800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525125600,"objectID":"ed9c6726c8ca239cc679f3d877e3b084","permalink":"https://www.newresalhaider.com/post/spec-stacular-spider-man/","publishdate":"2018-04-29T00:00:00+02:00","relpermalink":"/post/spec-stacular-spider-man/","section":"post","summary":"An introduction to the clojure.spec specification library with Spider-Man and Clojure.\n","tags":["Clojure","clojure.spec","knowledge representation","software contracts","specs"],"title":"Spec-stacular Spider-Man","type":"post"},{"authors":null,"categories":null,"content":" Programmers, like professionals in other fields, are passionate about their tools. One of the main elements in the toolbox of coders are programming languages. They allow their users to express solutions through code to tackle a large variety of problems in many domains.\nProgramming is also an art, as described in the article by Donald Knuth titled Computer Programming as an Art and in certain aspects of programming languages can be seen as art styles.\nAs can be expected with many things that people are passionate about, whether viewed as a tool or an art style, coders can bond or argue about programming languages. Like philosophers of old, these discussions can go quite into depth, but to the outsider the arguments made or the sentiments behind them can be quite opaque.\n If programming languages existed back then, I am sure they would be a hotly argued topic.  School of Athens by Raphael   Here I hope to shed some light to the casual observer on what makes programmers passionate about these languages and why some prefer one over the other. Such analysis can be quite subjective, and very much dependent on the writers experiences and preferences, but I will try my best to give an impartial overview.\nIn theory many general purpose programming languages are capable of doing the same things. The most commonly used programming languages are Turing complete, meaning that they can all simulate the workings of any Turing machine. Without getting into the full description of what a Turing machine is, for the reader unfamiliar with the concept, this means that any of the languages can express programs for similar tasks.\nThere are thousands of programming languages. Some older, and going back to the 50s, 60s and 70s and with considerable use still. Others have been released as recently as the last 10 years, and have gained considerable following. Given as I have mentioned that theoretically all these languages can do the same things, one could wonder why new languages are designed.\nHistory Historically, the original computers were instructed by a pure machine language, for example 0s and 1s. Writing programs this way can be tedious and error prone, and the results code can be very difficult to read. This is one of reasons why assembly languages were created. These are languages that are still very much tied into the instruction set of a particular machine, but in a more human readable form, where symbolic names are given for machine instructions. These would be then translated to the pure machine language, to instruct the machine.\nWhile reading and writing programs becomes easier this way, using assembly languages still has disadvantages. First, these languages are still very much tied to the hardware. Different instruction architectures can mean that a program for the same goal would have to be written differently for each architecture. Second, for many the instructions that one has to write this way are still very low level. The argument is made that with a better set of abstractions over assembly, programs can be written in a better way. A program written with such abstractions could be translated, compiled, to the required machine code specific for the required architecture.\nThe question of which abstractions need to be utilized is at the heart of why there are so many different programming languages. People have different ideas on what these abstractions might be, what the benefits and drawbacks of applying them are. This is at the heart of why people design and use newer programming languages. In the following sections we go through some of the aspects on these abstractions.\n Much like with ancients wonders of next to a modern city, with programming languages old also gives rise to the new, and often co-exists with it .  The Giza Pyramids © Robbster1983   Paradigms and Style As mentioned before, there are different opinions on how programs could be constructed. There are various subjects about on which people have opinions about: how the code is organized and how it is executed, among other elements. This is very much similar to how art styles function. For example the same subject can be painted in two differing styles.\n The Last Supper (Leonardo da Vinci) one of the most famous Renaissance style paintings.    The Last Supper (Tintoretto) depicts the same subject but in a Mannerist, proto-Baroque style.   Programming languages can be be classified on the different styles, programming paradigms based on the common elements in the approaches. Some paradigms include:\nImperative Imperative code can be seen as a set of commands for the computer to perform. This type of paradigm matches very strongly with how computer hardware is working, as nearly all computer hardware is designed the execute machine language, which is in itself is written in imperative style.\nProcedural One of the ways one can structure a program is to group together a series of commands. These groups, procedures, can then be called, used or reused as a single entity.\nObject-Oriented Object oriented code uses the notion of objects to organize code. An object is an encapsulation of related state and behavior. For example, consider a software that needs to represent a vehicle. The elements of the state that describe the object, such as colour and make, are called attributes. Various functionality related to the object, such as calculating the price of the car, are called methods. These concepts allow reuse, as the objects for a car and a motorcycle can share functionality.\nDeclarative In declarative programming, one describes, or more aptly declares what the problem is as opposed to detailing the steps on how to solve it. This contrasts with imperative programming, where one gives the instructions on how to solve it directly.\nFunctional Functional programming is one form of declarative programming where programs are constructed using functions, which are analogous and inspired by to mathematical functions. The intention is that these functions are ideally side effect free: their output is dependent solely on their input. This can make code easier to understand and allows for easier use of code written this way.\nLogic The logic paradigm is based around expressing code as a set of logical axioms. These axioms can then be used as a from of knowledge base to derive new knowledge and query. The programs themselves then can be posed as a query in this system. For example, if the knowledge is defined with the axioms \u0026ldquo;Tweety is a bird\u0026rdquo; and \u0026ldquo;Birds are animals\u0026rdquo;, the system should be able to answer the queries: \u0026ldquo;Is Tweety and animal?\u0026rdquo;.\nA language can focus on supporting a particular paradigm heavily or have a strong preference for it. For example Haskell or Clojure lean quite heavily on the functional paradigm, while Prolog is one of the main logic programming languages. Others, provide an explicit merge of various methodologies, such as Scala that combines elements of object orientation and functional programming.\nPreference for a particular language can go beyond the programming paradigms used. Syntax, the structure of how code is written, can matter quite a bit for person\u0026rsquo;s view on a particular language. For example Python uses indentation for managing the control flow of the code, as opposed to symbols in other languages.\nSuch preference can go even beyond the actual code itself to the tools one uses to write. While any text editor for editing text can often suffice, people can have differing expectations with regards to integrated development environments (IDEs) or other tools to edit and analyze the code. The lack or existence of specific tooling can also be a factor when deciding between languages.\nAvailable Code and Libraries Most coding is done with a particular purpose in mind, and it is rarely the case that the programmer can build everything from the ground up for such a task. In order to build interesting programs, one has to utilize existing knowledge, much like someone would utilize knowledge in a library to come to new insights.\n  The Bibliotheca Alexandrina. Photo © Carsten Whimster licensed under CC BY 3.0 .   Existing code can be used as a foundation from which the program can be built. Roughly speaking existing code comes in three main forms. It is either being part of the language (often called the standard library of the language), some external libraries extending the language for a particular purpose, or an existing code base of the application that one can improve upon.\nThe standard library contains various functionality included with the language itself. For example ways of manipulating files, various connection protocols, support for certain file formats, etc. Of course it is very much helpful if particular support for a certain feature that aims to use is already available with the language itself. This means less code to write and connect. On the other hand there is also some tension with regards to including too many features in the standard library, especially if certain parts of it become outdated, which enlarges the language and makes it more unwieldy.\nThe external libraries that one can use in a language can also influence the choice of a language. Certain languages have a lot of library support for specific tasks. For example Python has a large and active following in the Data Science community. Other languages have a lot of support for many different tasks simply due their age and user base such as Java. By using libraries one does not need to implement certain features from scratch but can reuse existing work and focus on their specific problem at hand.\nFinally, not all development starts from scratch, often one has to make additions or improvement to an existing program, in which case the choice of the language has already been made. While a rewrite of the code can often be tempting, linking between two code programming languages is not always trivial. It is often a good idea to continue with an existing language.\nThere are some exceptions to this as some languages have been designed with the ground up to inter-operate with other languages. A good example of this is Clojure has great interop with Java and/or JavaScript. This allows it to leverage existing libraries already written, and makes it much more attractive to use.\nExisting Knowledge Writing code is rarely trivial, and neither is learning new programming languages. Although previous experience helps, especially when dealing with languages with known paradigms, due to slight or large differences it can take a while to get used to the new language and libraries. With constantly looming deadlines and pressure to deliver, it can make sense to minimize the work that needs to be done. It is perfectly valid to work with a language that one already knows.\nCuriosity On the other hand learning a new language, especially in a new paradigm or other innovative features, can be quite interesting. It not only allows for work on existing code written in the new language but it also gives insights in how to program which is beneficial as a programmer in general no matter what language he is using.\nSpeed As mentioned earlier, commonly used programming languages are abstractions over machine code that can do more of less the same thing computationally. What abstractions are used however can influence the speed of executing the program, as well as the time of translating the code in the programming language to machine code.\nA common abstraction that can influence the speed of executing the program is how memory is managed. During the running of a program certain information needs to be stored. A way to do this is to allocate space in the computers memory, keep it around while needed and remove it afterwards. This latter portion, can be quite difficult to manage manually, as if one does it prematurely the program might crash or have other bugs. Not removing it would fill the memory with garbage, which makes the program use up more and more memory till it crashes.\nA solution to these problems is automatic garbage collection: a way for the computer to automatically manage and clean up memory. While this is a good solution in many cases, this process comes with an overhead, and can be unpredictable when the time and resource consuming cleanup happens. In most cases this overhead is trivial to pay for eliminating a whole suite of potential bugs. However in certain scenarios, such as real-time high performance games, it could be too much to pay.\nThe other issue of speed, translating the code from the programming language to machine code, can also be a consideration. Development requires making changes to code and checking whether the changes work. If the process of getting feedback takes a long time, due to these translations, it can destroy a programmers productivity. Golang is a language that is explicitly designed for fast compilation.\nSafety Safety is in many cases the flip side to the speed argument. Certain abstractions cost you in speed but provide you with safety in return. Different languages tend to make different trade-offs with this regard. For example one of the relatively new languages, Rust aims at focus on zero cost abstractions: abstractions with little to no run-time performance penalty.\nOne contentious aspect of safety is the use of type systems. Types allow the coder to specify various categories, such as numbers, persons, cars, etc as well as their requirements to be fulfilled within the context of the program. Types can be checked both statically, before the system is run, or dynamically, during the running of the program. Some people swear by very expressive type systems: where types can specify very detailed features of the things the program wants to represent. This then can be used for checking code for correctness, both before and during the running of a program, as well as documentation. On the other hand type checking is not free: it can make translating the compilation into machine code a much slower process. Some people also consider the writing and checking of types themselves very cumbersome during initial development, where quick iteration can be slowed down by specifying detailed types.\nThere is a whole spectrum of possible stances with regards to type systems. For example, certain languages such as Haskell and Idris are designed from the ground up with very expressive type systems that are statically checked. Others, for example Dart which started off as having optional types but adds mandatory types in the latest iteration to help with tooling, take a more balanced approach. Golang explicitly has a static, but minimalist, type system that allows for fast compilation. There are also languages, such as Clojure that instead of static types, use contract systems to ensure safety at run-time and allow for documentation and testing.\nDeployment While most general purpose programming languages can be made to run in all environments, they are not always available. In certain environments, such as mobile or on the web, only specific languages are supported. For example on Android Java and Kotlin are officially supported, while on the web JavaScript is the current Lingua Franca of the web. This means that it can be quite a herculean effort to make other languages work in such environments, and going with the most supported option is easier.\nThe way certain languages can get around on this hindrance is by using the more commonly supported language as the target to translate into. For example ClojureScript compiles into JavaScript. And in some cases, other developers have made the effort to get frameworks up and running that allow the use of a different language, such as the use of React Native and Flutter that allow the use of JavaScript and Dart respectively to develop mobile applications.\nThe Team and Beyond One final aspect of choosing a programming language, which can be surprisingly significant, is which language is beneficial to the team, as opposed to an individual developer. Different teams bring different expertise to the table, and while most professionals are often quite willing and able to use a new language if it is most suited to the task at hand, this can still be a cost that might be better spent on developing the application. From an employers perspective it can also often be beneficial to stick to more commonly used languages as it can be easier to find future employees versed in the language used. On the other hand, there are many professionals that would be quite willing to jump on the chance of using the latest programming languages, in which case the choice for a newer or more niche language can be a competitive advantage from a recruiting perspective.\nConclusion I hope this article gave some insight on why programmers pick and argue about programming languages. Despite all the various differences and arguments it is also very important to note, that great software has been written in many different languages, that is both excellent code and solves important problems. And while picking the right tool for the job is an important, it can be just an aspect of the art of solving problems with code.\n","date":1521327600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521327600,"objectID":"ccd23549de48d9718a624c652c8a2012","permalink":"https://www.newresalhaider.com/post/art-of-choosing-language/","publishdate":"2018-03-18T00:00:00+01:00","relpermalink":"/post/art-of-choosing-language/","section":"post","summary":"An exploration of why programmers prefer certain programming languages over others.\n","tags":["programming languages","art","Clojure","Dart","Golang","Idris","Haskell","Java","JavaScript","Python","Scala","ClojureScript","Kotlin","Prolog","Rust","React Native","Flutter"],"title":"The Art of Choosing a Programming Language","type":"post"},{"authors":null,"categories":null,"content":"This article contains some very minor spoilers for the Blade Runner 2049 movie. If you have not seen it yet, by all means do, it is really good.\n\u0026ldquo;And blood-black nothingness began to spin\u0026hellip; A system of cells interlinked within cells interlinked within cells interlinked within one stem\u0026hellip; And dreadfully distinct against the dark, a tall white fountain played.\u0026rdquo;\n Pale Fire by Vladimir Nabokov  Cover of the novel Pale Fire © Berkley Medallion   The above is a quote from the poem Pale Fire. It occurs in the novel titled Pale Fire by Vladimir Nabokov which has been recently used in the movie Blade Runner 2049. In the movie it was part of the Baseline test, a way to test the emotional response of a Replicant. The reason they undergo this process is because their creators fear that the connections they might make in their lives would give them emotions that would interfere with their intended purpose.\n Blade Runner 2049  Poster for the movie © Columbia Pictures   In life, such relationships always surround us. They are not just between people, but in our work, in our beliefs, in our art and in the knowledge we represent.\nSuppose we intend to describe the link between the movie Blade Runner and the book Pale Fire. We can summarize this information with a number of facts.\nBlade Runner is a movie. Blade Runner has a character named K. K is a Replicant. Replicants must pass a Baseline Test. Baseline Test is based on the poem Pale Fire. Pale Fire is written by Vladimir Nabokov.  The above facts show that the links that can tie together various pieces of knowledge. One can trace the connections from a simple description of a movie, released in 2017, to the author Vladimir Nabokov, as was intended by the writers of the movie.\nAlthough the above recitation of facts is easy to follow, from a knowledge representation perspective one can find some issues with it.\nFirst the description is imprecise. As the Blade Runner could refer to the newer Blade Runner 2049 movie as opposed to the 1982 original titled Blade Runner.\n The first movie titled Blade Runner  Blade Runner movie poster © 1982 The Ladd Company   Second the set of facts is incomplete. The poem Pale Fire is indeed written by Vladimir Nabokov, but it is presented in the book Pale Fire, also written by Nabokov as the work of the fictional poet John Shade. The set of facts here fails to make the explicit distinction between Pale Fire (poem) and Pale Fire (book), and that the poem is contained in the book.\nThird, and perhaps most importantly, the above list of facts relies a lot on the users grasp of the English natural language. For a program, it can be surprisingly difficult to understand the relationships such as \u0026ldquo;is a\u0026rdquo;, \u0026ldquo;is based on\u0026rdquo;, \u0026ldquo;named\u0026rdquo;, etc between the various elements in the text.\nThese issues seem somewhat nit-picky, as this information can be derived from the rest of the article. However this means that the knowledge in the summary does not stand on its own. If those facts are detailed without the rest of the article, or if the reader of them is a machine, and not a person that can easily add some context, they might lead them to incorrect or insufficient conclusions. They might get wrong information that the 1982 movie Blade Runner has a character named K, or fail to see the link that poem is contained in the book by the same author. And although in the case of Blade Runner, these issues might seem small, this is different if the knowledge relates to financial, legal or clinical domains. Here, mistakes or omissions can be costly.\nHaving a larger list of more detailed facts can help with these issues, but to a certain extent they still remain due to the ambiguity of the natural language. In addition the fact that is often very easy to skip over implicit details. This is especially true for the issue of a computer not being able to make (enough) sense of this information.\nA proposed solution to these issues is Linked Data and in particular Resource Description Framework (RDF), with which Linked Data data can be expressed. These technologies allow us to represent the above facts in a more formal and precise way, that can make it both human and machine read- and write-able.\n Resource Description Framework  Logo of RDF © W3C   One significant feature of RDF is that requires precise naming. Many elements of it are either a International Resource Identifier (IRI) or some raw data-types. Good examples of the former are URLs, such as the link to this website: http://www.newresalhaider.com , that allows one to find a web resource. Examples of the later are texts or numbers, such as \u0026ldquo;Blade Runner\u0026rdquo; or 15 respectively.\nThe other significant feature of RDF is that most knowledge is represented as a set of facts, where each fact is expressed as subject, predicate object triples. For example the fact \u0026ldquo;Blade Runner is a movie\u0026rdquo; is expressed with the subject \u0026ldquo;Blade Runner\u0026rdquo; the predicate \u0026ldquo;is a\u0026rdquo; and the object \u0026ldquo;movie\u0026rdquo;.\nPutting this together in RDF (using the Turtle notation) you would get a triple such as:\n\u0026lt;http://www.newresalhaider.com/ontologies/bladerunner/blade-runner\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;http://www.newresalhaider.com/ontologies/bladerunner/movie\u0026gt;.  This example is an RDF way of saying \u0026ldquo;Blade Runner is a type of movie\u0026rdquo; or alternatively \u0026ldquo;Blade runner is a movie\u0026rdquo;. This type of representation shows us a couple of benefits. First we are now being more precise as each element in the triple can refer to one specific resource, for example Blade Runner or Movie, where there IRI makes sure we do not necessarily confuse the term with anything else. Second this also shows off the fact that you can link to resources from different places: the predicate \u0026ldquo;type\u0026rdquo; is from a completely different domain. This allows us to re-use knowledge that has already been defined. As one can expect saying something is of a \u0026ldquo;type\u0026rdquo;, for example an apple is a type of a fruit, is actually very common. This is one of the main strengths of what makes Linked Data so powerful, one can re-use knowledge already stated.\nTyping out the full IRI each time can be pretty bothersome, and it does not help the readability either. Thankfully we can define a common prefix we use separately, and just write the last part of the IRI in each case. In this case we define a base prefix and we refer to subject and object by \u0026ldquo;\u0026lt;#blade-runner\u0026gt;\u0026rdquo; and \u0026ldquo;\u0026lt;#movie\u0026gt;\u0026rdquo; respectively.\n@base \u0026lt;http://www.newresalhaider.com/ontologies/bladerunner\u0026gt; . \u0026lt;#blade-runner\u0026gt; \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type\u0026gt; \u0026lt;#movie\u0026gt;.  We can do similar things when linking elements that have been already defined elsewhere. In this case we define a prefix to use as an abbreviation while writing:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/bladerunner\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . \u0026lt;#blade-runner\u0026gt; rdf:type \u0026lt;#movie\u0026gt;.  In practice, \u0026ldquo;rdf:type\u0026rdquo; as a predicate is so common that there is an even simpler notation. We can use \u0026lsquo;a\u0026rsquo; as a predicate, which is in line with what we intend to express: \u0026ldquo;Blade Runner is a movie\u0026rdquo;.\nThe resulting RDF facts look as follows (note that the rdf prefix could be omitted here as the \u0026ldquo;a\u0026rdquo; abbreviation does not make it necessary):\n@base \u0026lt;http://www.newresalhaider.com/ontologies/bladerunner\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . \u0026lt;#blade-runner\u0026gt; a \u0026lt;#movie\u0026gt;.  If we aim to write something that is just a text as a subject, say when referring to the title of a movie , we can do that as well:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/bladerunner\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . \u0026lt;#blade-runner\u0026gt; a \u0026lt;#movie\u0026gt;. \u0026lt;#blade-runner\u0026gt; \u0026lt;#title\u0026gt; \u0026quot;Blade Runner 2049\u0026quot;.  With this way of writing, we can actually rewrite our original set of facts as follows:\n@base \u0026lt;http://www.newresalhaider.com/ontologies/bladerunner\u0026gt; . @prefix rdf: \u0026lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026gt; . @prefix foaf: \u0026lt;http://xmlns.com/foaf/0.1/\u0026gt; . \u0026lt;#blade-runner\u0026gt; a \u0026lt;#movie\u0026gt;. \u0026lt;#blade-runner\u0026gt; \u0026lt;#title\u0026gt; \u0026quot;Blade Runner 2049\u0026quot;. \u0026lt;#blade-runner\u0026gt; \u0026lt;#has-character\u0026gt; \u0026lt;#K\u0026gt;. \u0026lt;#K\u0026gt; foaf:name \u0026quot;K\u0026quot;. \u0026lt;#K\u0026gt; a \u0026lt;#replicant\u0026gt;. \u0026lt;#replicant\u0026gt; \u0026lt;#must-pass\u0026gt; \u0026lt;#baseline-test\u0026gt;. \u0026lt;#baseline-test\u0026gt; \u0026lt;#based-on\u0026gt; \u0026lt;#pale-fire-poem\u0026gt;. \u0026lt;#pale-fire-poem\u0026gt; \u0026lt;#included-in\u0026gt; \u0026lt;#pale-fire-book\u0026gt;. \u0026lt;#pale-fire-book\u0026gt; \u0026lt;#written-by\u0026gt; \u0026lt;#nabokov\u0026gt;. \u0026lt;#nabokov\u0026gt; foaf:name \u0026quot;Vladimir Nabokov\u0026quot;.  With this version we suddenly defined our list of facts in a more formal manner than previously. This makes it much more simpler for machines to understand this set of facts. In fact we actually used the Friend of a Friend (FOAF) ontology to use the notion of name that is also used when talking about relationships between people. In fact, one could argue that using an existing movie dataset, such as the Linked Movie Database would have been even better, which we will leave as an exercise for the reader.\nHopefully I could show a glimpse of the possibilities the Semantic Web for which Linked Data forms the basis, with this example. Of course the above is just scratching the surface of what it can be done with RDF, Linked Data. With each addition, our set of facts could grow. One could go beyond a single movie and build a document of poems that are references in movies, or a knowledge base of the Blade Runner franchise. It might be easier than one expects, due to the fact that knowledge, much like people are\u0026hellip;\nInterlinked.\n","date":1518912000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518912000,"objectID":"b49faefe6990b72cd668a5b4f33da548","permalink":"https://www.newresalhaider.com/post/interlinked-data/","publishdate":"2018-02-18T00:00:00Z","relpermalink":"/post/interlinked-data/","section":"post","summary":"A Linked Data introduction with Blade Runner 2049.\n","tags":["triples","knowledge representation","reasoning","RDF","Linked Data","Semantic Web"],"title":"Data Interlinked","type":"post"},{"authors":null,"categories":null,"content":"In the Star Trek episode \u0026ldquo;The Trouble with Tribbles\u0026rdquo; the crew of the starship Enterprise encounters creatures called Tribbles. They are cute, simple creatures of mysterious origin that seem harmless at first but when they multiply the pose a big problem for the ship and the crew.\n Tribbles  Tribbles © 1967 Paramount Pictures   Representing and reasoning with knowledge have surprisingly similar problems. A single fact on its own is a relatively straightforward affair. A fact, such as \u0026ldquo;Tribbles are cute\u0026rdquo; can be represented with only three parts of a triple: a subject Tribbles, a predicate are and an object cute. Things can get quite a bit more difficult when there are more facts/triples: \u0026ldquo;Tribbles are round\u0026rdquo;, \u0026ldquo;Tribbles are furry\u0026rdquo;, \u0026ldquo;Tribbles originate from Iota Geminorum IV\u0026rdquo;, and other millions of facts that one could have about such a species. This is especially true when one takes into the account that the fact that knowledge can be interlinked \u0026ldquo;Iota Geminorum IV is a planet\u0026rdquo;, \u0026ldquo;Iota Geminorum IV is also known as Fafniri\u0026rdquo;, \u0026ldquo;Iota Geminorum IV is also known as Tribble Prime\u0026rdquo;.\nThis makes representing and reasoning with facts a non-trivial process. A system that holds all this knowledge should be able to answer a query such as \u0026ldquo;Do Tribbles originate from Fafniri?\u0026rdquo; with a yes, based on the facts \u0026ldquo;Tribbles originate from Iota Geminorum IV\u0026rdquo;, \u0026ldquo;Iota Geminorum IV is a planet\u0026rdquo; and \u0026ldquo;Iota Geminorum IV is also known as Fafniri\u0026rdquo;, even in the context of millions of other triples.\nAnother interesting issue with representing facts is the context of the information. To us the viewers, and initially to the crew of the Enterprise, Tribbles look like harmless and adorable creatures. To the Klingons they are an ecological menace and their mortal enemies. How such \u0026ldquo;knowledge about knowledge\u0026rdquo; is represented and used is often a challenging problem.\nVarious technologies have been proposed to deal with the above-mentioned issues. The Semantic Web technologies of Linked Data and Ontologies in particular have been designed around solving many of these problems. Nonetheless there is room for improvement. In the future I hope to be able to explain how these techniques can be utilized and perhaps lessen the pain points that currently surround (the use of) them.\n","date":1517094000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517094000,"objectID":"a23dbe5f09ba4f80f78087cf3921e50c","permalink":"https://www.newresalhaider.com/post/trouble-with-triples/","publishdate":"2018-01-28T00:00:00+01:00","relpermalink":"/post/trouble-with-triples/","section":"post","summary":"A brief peek into some issues in knowledge presentation and reasoning.\n","tags":["triples","knowledge representation","reasoning"],"title":"The Trouble with Triples","type":"post"},{"authors":null,"categories":null,"content":"Welcome to the first post on my blog on which hopefully many will follow. My intention is to write about knowledge representation, reasoning, AI and coding, in an easily digestible but in depth-way.\n","date":1515884400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515884400,"objectID":"bc9ba641cd9b12de89ca4c7e66bb5cbc","permalink":"https://www.newresalhaider.com/post/introduction/","publishdate":"2018-01-14T00:00:00+01:00","relpermalink":"/post/introduction/","section":"post","summary":"A bit of an introduction.\n","tags":["introduction","knowledge representation","AI","reasoning"],"title":"Introduction","type":"post"},{"authors":null,"categories":null,"content":"Regulatory compliance is the goal of an organization to ensure it complies with all the relevant policies, regulations and laws. Failure to comply can have grave consequences for an organization, with huge fines and penalties being imposed. Regulatory pressure has been increasing over the years, with new and more complex regulation being enacted. This is especially true for the financial sector, where in the wake of the financial crisis, new policies and laws where enacted, both internal and external, to prevent a similar crisis happening in the future.\nThese new and changing policies and laws give a huge challenge for financial organizations. These issues get compounded by fact that in a global world, internal, national and international regulations create an interwoven set of rules that need to be interpreted and applied on various financial products and services. Ensuring this compliance, is a time and expertise intensive task that often needs to be done manually. Automating these tasks is a huge challenge due to the fact that more traditional techniques are often ill equipped to tackle such an ever changing and complex domain in a way that is transparent to the domain experts and regulators.\nIn this project, the goal is to find innovative techniques and solutions to the issue of regulatory compliance in the legal and financial domain.\n","date":1514678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514678400,"objectID":"ed85a23f8bb84f3aad3e3da2dcedf286","permalink":"https://www.newresalhaider.com/project/legal-banking-compliance/","publishdate":"2017-12-31T00:00:00Z","relpermalink":"/project/legal-banking-compliance/","section":"project","summary":"Machine enabled compliance checking in the legal and financial domain.","tags":["law","banking","AI","Semantic Web","FinTech","regulations"],"title":"Legal Regulatory Compliance Within The Financial Domain.","type":"project"},{"authors":null,"categories":null,"content":"","date":1514592000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514592000,"objectID":"545c472c36ba27b59c09d3e0e6a4da26","permalink":"https://www.newresalhaider.com/project/innius/","publishdate":"2017-12-30T00:00:00Z","relpermalink":"/project/innius/","section":"project","summary":"Smart software for managing and understanding industrial assets.","tags":["industrial","sensors"],"title":"Smart Industry Software","type":"project"},{"authors":null,"categories":null,"content":"The time of clinical health professionals is incredibly valuable. Software can alleviate the burden of physicians, nursers and other health experts and allow them to provide better, more effective health care to patients.\nCreating, maintaining and using software in clinical environments is a difficult process. Not only it is paramount that such software needs to be correct, it has to have an understanding of highly domain specific knowledge about clinical processes in order to provide beneficial support to health professionals.\nSemantic Web technologies, in particular anthologies enable better clinical software. Ontologies allow for a formal and explicit way to model knowledge that is understandable for both clinicians and machines alike.\n","date":1514505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514505600,"objectID":"cf5a879395b3f1eb11e4cc138eeea1ef","permalink":"https://www.newresalhaider.com/project/clinical-semantics/","publishdate":"2017-12-29T00:00:00Z","relpermalink":"/project/clinical-semantics/","section":"project","summary":"Using Semantic Web based technologies to create smarter, automated clinical software.","tags":["Semantic Web","health","clinical","SNOMED CT"],"title":"Ontology Enabled Clinical Software","type":"project"},{"authors":null,"categories":null,"content":"Software bugs and errors have a monumental negative impact on society. Not only can they have huge monetary cost, ranging into billions of dollars annually in the United States alone, but in some cases can even lead to disasters that lead to the loss of life. Preventing such issues from happening requires a large amount of effort in designing and maintaining software.\nHowever designing and maintaining error free software remains a difficult problem. Not only is software getting more complex, its correct functioning often depends on highly specific domain knowledge of its purpose and its environment. Therefor manually checking the correctness of the software is expensive in both time and available expertise.\nA potential solution that was proposed for this is using machine understandable domain knowledge to help automate software maintenance tasks. Formal ontologies have been proposed and used in various fields to make domain knowledge explicit and usable for both humans and software. In particular during my thesis work, titled \u0026ldquo;An Ontology Based Framework for Specification Mining and Dynamic Program Analysis\u0026rdquo;, the use of ontologies to help understand the working of a running program were successfully explored. In particular it was shown that for a category of bugs, general ontologies such as WordNet, can be used find issues issues from program traces.\n","date":1513900800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513900800,"objectID":"599f3e60f666be3a864f13d55de2aefd","permalink":"https://www.newresalhaider.com/project/semantic-software-analysis/","publishdate":"2017-12-22T00:00:00Z","relpermalink":"/project/semantic-software-analysis/","section":"project","summary":"The automated analysis of software using ontologies and dynamic program information.","tags":["software","program analysis","dynamic analysis","Semantic Web","program traces"],"title":"Semantic Aware Software Analysis","type":"project"},{"authors":["Newres Al Haider","Samina Abidi","William Van Woensel","Syed SR Abidi"],"categories":null,"content":"","date":1414368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1414368000,"objectID":"efee6028f8d23ac6d02964a6c52be372","permalink":"https://www.newresalhaider.com/publication/medical-data-semantic/","publishdate":"2014-10-27T00:00:00Z","relpermalink":"/publication/medical-data-semantic/","section":"publication","summary":"Semantic Web technologies have shown to have great potential in many different domains, to facilitate knowledge representation, exchange and reasoning, in a formal and yet both human and machine understandable way. In particular, within the health domain, they enable knowledge integration and understanding by explicitly defining and linking concepts and relationships using ontologies to information within clinical knowledge bases. This additional metadata also allows for automated decision support and semantic based analytics to be implemented, that facilitate improved healthcare at a lower cost. Unfortunately many existing datasets in healthcare environments are still stored in relational databases, as opposed to using semantic technologies. Due to this, the link with explicit metadata is often lacking or non-existent. Furthermore, both the databases and the clinical terminologies can be considerably large, making the mapping and subsequent uses of the information a difficult process. In a full fledged decision support system the level and accuracy of the mapping can greatly influence the effectiveness of any subsequent analysis and decision support tasks. This is especially true in clinical scenarios, where very large and complex sets of terms need to be mapped to relational databases. In this paper we aim to provide a general approach for interlinking relational data with clinical ontology based metadata that allows for a fine grade evaluation, with respect to the mapping's impact on analytics. We evaluate our approach by mapping information from clinical terminologies, such as SNOMED CT, to a large laboratory dataset contained in a relational database, with the goal of creating a full fledged, semantically enabled, analytics and decision support system.","tags":null,"title":"Integrating existing large scale medical laboratory data into the semantic web framework","type":"publication"},{"authors":["William Van Woensel","Newres Al Haider","Ahmad Marwan Ahmad","Syed SR Abidi"],"categories":null,"content":"","date":1413676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413676800,"objectID":"689c551022fca56a4a3987a180d8b9b9","permalink":"https://www.newresalhaider.com/publication/benchmark-framework/","publishdate":"2014-10-19T00:00:00Z","relpermalink":"/publication/benchmark-framework/","section":"publication","summary":"Semantic Web technologies are used in a variety of domains for their ability to facilitate data integration, as well as enabling expressive, standards-based reasoning. Deploying Semantic Web reasoning processes directly on mobile devices has a number of advantages, including robustness to connectivity loss, more timely results, and reduced infrastructure requirements. At the same time, a number of challenges arise as well, related to mobile platform heterogeneity and limited computing resources. To tackle these challenges, it should be possible to benchmark mobile reasoning performance across different mobile platforms, with rule- and datasets of varying scale and complexity and existing reasoning process flows. To deal with the current heterogeneity of rule formats, a uniform rule- and data-interface on top of mobile reasoning engines should be provided as well. In this paper, we present a cross-platform benchmark framework that supplies 1) a generic, standards-based Semantic Web layer on top of existing mobile reasoning engines; and 2) a benchmark engine to investigate and compare mobile reasoning performance.","tags":null,"title":"A cross-platform benchmark framework for mobile semantic web reasoning engines","type":"publication"},{"authors":["William Van Woensel","Newres Al Haider","Patrice C Roy","Ahmad Marwan Ahmad","Syed SR Abidi"],"categories":null,"content":"","date":1407715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1407715200,"objectID":"9db1354d1a32bafc089d1b262516fdb2","permalink":"https://www.newresalhaider.com/publication/comparison-mobile-rule-engines/","publishdate":"2014-08-11T00:00:00Z","relpermalink":"/publication/comparison-mobile-rule-engines/","section":"publication","summary":"Semantic Web technology is used extensively in the health domain, due to its ability to specify expressive, domain-specific data, as well as its capacity to facilitate data integration between heterogeneous, health-related sources. In the health domain, mobile devices are an essential part of patient self-management approaches, where local clinical decision support is applied to ensure that patients receive timely clinical findings. Currently, increases in mobile device capabilities have enabled the deployment of Semantic Web technologies on mobile platforms, enabling the consumption of rich, semantically described health data. To make this semantic health data available to local decision support as well, Semantic Web reasoning should be deployed on mobile platforms. However, there is currently a lack of software solutions and performance analysis of mobile, Semantic Web reasoning engines. This paper presents and compares the mobile benchmarks of 4 reasoning engines, applied on a dataset and rule set for patients with A trial Fibrillation (AF). In particular, these benchmarks investigate the scalability of the mobile reasoning processes, and study reasoning performance for different process flows in decision support. For the purpose of these benchmarks, we extended a number of existing rule engines and RDF stores with Semantic Web reasoning capabilities.","tags":null,"title":"A comparison of mobile rule engines for reasoning on semantic web based health data","type":"publication"},{"authors":["Patrice C Roy","Newres Al Haider","William Van Woensel","Ahmad Marwan Ahmad","Syed SR Abidi"],"categories":null,"content":"","date":1403049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1403049600,"objectID":"e7f600ba3a587fd3f381d50a2d0c5de1","permalink":"https://www.newresalhaider.com/publication/towards-cdss-mobile/","publishdate":"2014-06-18T00:00:00Z","relpermalink":"/publication/towards-cdss-mobile/","section":"publication","summary":"Assistive technologies in smart environments were developed in order to maintain and improve the quality of life of people with dementia or other health problems. In order to provide adequate support at the opportune moment, it is necessary to deploy ambient services, such as activity recognition and assistance planning. Clinical Decision Support Systems (CDSS) that implement clinical guidelines, allow for the right clinical decisions, such as diagnoses and treatment choices, to be made automatically based on patient data and other health information. While data derived from smart home services can be used in these CDSS, smart homes can be used to provide services related to clinical decisions. Mobile devices can be used in conjunction with the smart home services and a remote CDSS for sending notifications or retrieve data from wearable or built-in sensors. However, in a context where smart homes interacts with a remote CDSS, we must take into account mobility (e.g. outdoors, work), failure tolerance (e.g. connection issues with remote CDSS) and privacy concerns in order to provide minimum quality of service. Thus, CDSS must be locally deployed as a smart home service and on a mobile device. In this paper we investigate a scenario where due to the above mentioned reasons a clinical guideline compliant CDSS needs to be deployed on a mobile device and as a smart home service, where clinical data can come from either the patient (manual input) or the smart home and mobile sensors. In particular we focus on implementing and evaluating a guideline for the diagnosis of sleep apnea. Sleep apnea diagnosis is a well-suited task for this purpose as attributes for the execution of the guideline could be collected both from the patient and sensor data inside or outside the smart home environment. In order to illustrate the feasibility of CDSS as smart home service and on mobile device, the Sleep Apnea CDSS is validated on an Android smartphone and show promising results.","tags":null,"title":"Towards Guideline Compliant Clinical Decision Support System Integration in Smart and Mobile Environments: Formalizing and Using Clinical Guidelines For Diagnosing Sleep Apnea","type":"publication"},{"authors":["Newres Al Haider","Benoit Gaudin","John Murphy"],"categories":null,"content":"","date":1317081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1317081600,"objectID":"11bfa2075abb07d1b078bd36eb0487fc","permalink":"https://www.newresalhaider.com/publication/execution-trace-analysis/","publishdate":"2011-09-27T00:00:00Z","relpermalink":"/publication/execution-trace-analysis/","section":"publication","summary":"Dynamic analysis is the analysis of the properties of a running program. In order to perform dynamic analysis, information about the running program is often collected through execution traces. Exploring and analyzing these traces can be an issue due to their size and that knowledge of a human expert is often needed to derive the required conclusions. In this paper we provide a framework in which the semantics of execution traces, as well as that of dynamic analyses, are formally represented through ontologies. In this framework the exploration and analysis of the traces is enabled through semantic queries, and enhanced further through automated reasoning on the ontologies. We will also provide ontologies to represent traces and some basic dynamic analysis techniques, along with semantic queries that enable these techniques. Finally we will illustrate our approach through an example.","tags":null,"title":"Execution Trace Exploration and Analysis using Ontologies","type":"publication"},{"authors":["Newres Al Haider","Benoit Gaudin","Paddy Nixon"],"categories":null,"content":"","date":1278892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1278892800,"objectID":"e08d2b713c4e8bf23a43338c743e38ab","permalink":"https://www.newresalhaider.com/publication/approach-da-ontologies/","publishdate":"2010-07-12T00:00:00Z","relpermalink":"/publication/approach-da-ontologies/","section":"publication","summary":"In this paper we present the possibility of using an ontology based framework in order to model Dynamic Analysis techniques. This work relies on similar ideas applied to the case of Static Analysis, in which ontologies are used to represent some knowledge about the programs to be analyzed. In the approach proposed in this paper we describe how ontologies can be applied to Dynamic Analysis by modeling both the information collected from the system, as well as some requirements about the type of analysis to be performed. Both of these ontologies can be designed by integrating ontologies previously defined during the software development cycle, allowing for re-usability. Finally, these ontologies make it possible to reason about concepts related to Dynamic Analysis and offer tools that facilitate automation. This paper presents the main ideas of the proposed approach and illustrates them with an example related to Frequency Spectrum Analysis.","tags":null,"title":"An Approach for Modeling Dynamic Analysis using Ontologies","type":"publication"}]